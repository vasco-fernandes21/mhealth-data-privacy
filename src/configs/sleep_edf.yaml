# ============================================================================
# SLEEP-EDF DATASET CONFIGURATION
# ============================================================================
# Optimized for baseline (no privacy) - standard ML practices

dataset:
  name: "sleep-edf"
  path: "data/processed/sleep-edf"
  
  # Data shapes
  n_features: 24
  n_channels: 24
  n_classes: 5
  sequence_length: 10  # Windowed epochs
  
  # Class names
  class_names:
    - "W"      # Wake
    - "N1"     # Stage 1
    - "N2"     # Stage 2
    - "N3"     # Stage 3/4
    - "R"      # REM

model:
  architecture: "lstm"
  lstm_units: 128
  lstm_layers: 2
  lstm_bidirectional: true
  dropout: 0.3
  dense_layers: [64, 32]
  activation: "relu"
  use_batch_norm: false  # For DP compatibility
  use_layer_norm: false
  use_group_norm: false

training:
  # Dataset-specific overrides
  batch_size: 32  # Smaller batch (less data)
  learning_rate: 0.0005
  # Other settings inherited from training_defaults.yaml
  # - epochs: 100
  # - optimizer: "adam"
  # - weight_decay: 1e-4
  # - loss: "cross_entropy"
  # - label_smoothing: 0.05
  # - use_class_weights: false
  # - lr_scheduler: "none"
  # - gradient_clipping: true
  # - gradient_clip_norm: 1.0
  # - early_stopping_patience: 10