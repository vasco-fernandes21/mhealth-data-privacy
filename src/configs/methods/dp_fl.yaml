# ================================================================
# FEDERATED LEARNING + DIFFERENTIAL PRIVACY
# ================================================================
method: "dp_fl"
description: "Federated Learning + Differential Privacy"

differential_privacy:
  enabled: true
  target_delta: 1e-5
  client_noise_multiplier: 0.3
  server_noise_multiplier: 0.5
  max_grad_norm: 1.0
  accounting_method: "rdp"
  poisson_sampling: true
  grad_sample_mode: "hooks"

federated_learning:
  enabled: true
  n_clients: 10
  global_rounds: 40
  local_epochs: 1
  aggregation_method: "fedavg"
  client_sampling_fraction: 1.0

training:
  batch_size: 256
  learning_rate: 0.001
  optimizer: "adamw"
  weight_decay: 0.0001
  scheduler: "cosine"
  scheduler_T_max: 40
  early_stopping_patience: 10
  num_workers: 0
  use_amp: false
  pin_memory: true