# ============================================================================
# WESAD DATASET CONFIGURATION
# ============================================================================

dataset:
  name: "wesad"
  path: "data/processed/wesad"
  
  # Data shapes 
  n_channels: 14              
  n_classes: 2
  sequence_length: 1920       # 60 seconds @ 32 Hz
  
  class_names:
    - "non-stress"
    - "stress"

model:
  architecture: "lstm"
  input_projection: 128
  lstm_units: 64
  lstm_layers: 2
  lstm_bidirectional: true
  dropout: 0.3
  dense_layers: [64, 32]
  activation: "relu"
  use_group_norm: true
  group_norm_groups: 8

training:
  # ✅ ADICIONE ESTES CAMPOS QUE FALTAM:
  optimizer: "adam"                    # ← ADICIONE
  label_smoothing: 0.05                # ← ADICIONE
  lr_scheduler: "reduce_on_plateau"    # ← Já tem, OK
  
  # Existentes
  epochs: 100
  batch_size: 64
  learning_rate: 0.001
  weight_decay: 1e-4
  
  loss: "cross_entropy"
  use_class_weights: true
  
  # Gradient clipping (para DP compatibility)
  gradient_clipping: true              # ← ADICIONE
  gradient_clip_norm: 1.0              # ← ADICIONE
  
  early_stopping: true
  early_stopping_patience: 8
  
  num_workers: 4
  prefetch_factor: 2
  drop_last: true