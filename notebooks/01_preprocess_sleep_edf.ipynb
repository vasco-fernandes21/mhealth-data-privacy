{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sleep-EDF Dataset Preprocessing\n",
        "\n",
        "Este notebook executa o pré-processamento completo do dataset Sleep-EDF.\n",
        "\n",
        "## O que este notebook faz:\n",
        "1. Carrega dados EDF (gravações EEG/EOG) e hypnogramas\n",
        "2. Aplica filtragem Butterworth\n",
        "3. Segmenta em épocas de 30 segundos\n",
        "4. Extrai features (tempo + frequência)\n",
        "5. Normaliza e divide em train/val/test\n",
        "6. Salva dados processados no Google Drive\n",
        "\n",
        "**⚠️ IMPORTANTE**: Execute este notebook apenas UMA VEZ. Os dados processados são salvos permanentemente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 1: Setup (run 00_colab_setup.ipynb first)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SLEEP-EDF PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import our preprocessing module\n",
        "from src.preprocessing.sleep_edf import preprocess_sleep_edf, load_processed_sleep_edf\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "RAW_DATA_PATH = '/content/drive/MyDrive/mhealth-data/raw/sleep-edf'\n",
        "PROCESSED_DATA_PATH = '/content/drive/MyDrive/mhealth-data/processed/sleep-edf'\n",
        "\n",
        "print(f\"Raw data path: {RAW_DATA_PATH}\")\n",
        "print(f\"Processed data path: {PROCESSED_DATA_PATH}\")\n",
        "\n",
        "# Check if raw data exists\n",
        "if not os.path.exists(RAW_DATA_PATH):\n",
        "    print(f\"❌ Raw data directory not found: {RAW_DATA_PATH}\")\n",
        "    print(\"Please download Sleep-EDF dataset and place it in the raw directory.\")\n",
        "    print(\"See data/README.md for download instructions.\")\n",
        "else:\n",
        "    print(\"✅ Raw data directory found\")\n",
        "    \n",
        "    # List available files\n",
        "    files = os.listdir(RAW_DATA_PATH)\n",
        "    edf_files = [f for f in files if f.endswith('.edf') and not f.endswith('.hyp.edf')]\n",
        "    hyp_files = [f for f in files if f.endswith('.hyp.edf')]\n",
        "    \n",
        "    print(f\"Found {len(edf_files)} recording files and {len(hyp_files)} hypnogram files\")\n",
        "    if edf_files:\n",
        "        print(\"Sample files:\", edf_files[:3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 2: Run Preprocessing\n",
        "# ============================================================================\n",
        "\n",
        "if os.path.exists(RAW_DATA_PATH) and len(edf_files) > 0:\n",
        "    print(\"Starting Sleep-EDF preprocessing...\")\n",
        "    \n",
        "    # Run preprocessing\n",
        "    preprocessing_info = preprocess_sleep_edf(\n",
        "        data_dir=RAW_DATA_PATH,\n",
        "        output_dir=PROCESSED_DATA_PATH,\n",
        "        test_size=0.15,\n",
        "        val_size=0.15,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PREPROCESSING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Preprocessing info: {preprocessing_info}\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ Cannot proceed without raw data files\")\n",
        "    print(\"Please download the Sleep-EDF dataset first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 3: Verify Processed Data\n",
        "# ============================================================================\n",
        "\n",
        "if os.path.exists(PROCESSED_DATA_PATH):\n",
        "    print(\"Verifying processed data...\")\n",
        "    \n",
        "    # Load processed data to verify\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, scaler, label_encoder, info = load_processed_sleep_edf(PROCESSED_DATA_PATH)\n",
        "    \n",
        "    print(f\"\\nData shapes:\")\n",
        "    print(f\"  Train: {X_train.shape}\")\n",
        "    print(f\"  Val:   {X_val.shape}\")\n",
        "    print(f\"  Test:  {X_test.shape}\")\n",
        "    \n",
        "    print(f\"\\nLabel distribution:\")\n",
        "    print(f\"  Train: {np.bincount(y_train)}\")\n",
        "    print(f\"  Val:   {np.bincount(y_val)}\")\n",
        "    print(f\"  Test:  {np.bincount(y_test)}\")\n",
        "    \n",
        "    print(f\"\\nClass names: {info['class_names']}\")\n",
        "    print(f\"Features per sample: {info['n_features']}\")\n",
        "    \n",
        "    print(\"\\n✅ Sleep-EDF preprocessing completed successfully!\")\n",
        "    print(\"Data is ready for training models.\")\n",
        "    \n",
        "else:\n",
        "    print(\"❌ Processed data not found. Please run preprocessing first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
