{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè• mHealth Privacy-Utility: Complete Training Pipeline\n",
        "\n",
        "**Executa todos os cen√°rios de treino:**\n",
        "- ‚úÖ Baseline (sem privacidade)\n",
        "- ‚úÖ DP (Differential Privacy, Œµ=1.0)\n",
        "- ‚úÖ FL (Federated Learning, 5 clientes)\n",
        "- ‚úÖ FL+DP (Federated + Differential Privacy)\n",
        "\n",
        "**Assumido:**\n",
        "- Dados preprocessados em `MyDrive/mhealth-data/processed/`\n",
        "- Projeto em `MyDrive/mhealth-privacy/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup: Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "setup"
        ]
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "print('‚úÖ Google Drive mounted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup: Define Paths & Verify Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "setup"
        ]
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Define paths\n",
        "DRIVE_BASE = Path('/content/drive/MyDrive')\n",
        "PROJECT_DIR = DRIVE_BASE / 'mhealth-privacy'\n",
        "DATA_BASE = DRIVE_BASE / 'mhealth-data'\n",
        "\n",
        "print('üìÅ Drive Structure Check:')\n",
        "print(f'   Project: {PROJECT_DIR.exists()} ‚Üí {PROJECT_DIR}')\n",
        "print(f'   Data: {DATA_BASE.exists()} ‚Üí {DATA_BASE}')\n",
        "\n",
        "# Check processed data\n",
        "sleep_edf_dir = DATA_BASE / 'processed' / 'sleep-edf'\n",
        "wesad_dir = DATA_BASE / 'processed' / 'wesad'\n",
        "\n",
        "print(f'\\nüìä Processed Data Check:')\n",
        "print(f'   Sleep-EDF: {sleep_edf_dir.exists()}')\n",
        "if sleep_edf_dir.exists():\n",
        "    files = list(sleep_edf_dir.glob('*.npy')) + list(sleep_edf_dir.glob('*.pkl'))\n",
        "    print(f'      Files: {len(files)}')\n",
        "    for f in sorted(files)[:5]:\n",
        "        print(f'      - {f.name}')\n",
        "\n",
        "print(f'\\n   WESAD: {wesad_dir.exists()}')\n",
        "if wesad_dir.exists():\n",
        "    files = list(wesad_dir.glob('*.npy')) + list(wesad_dir.glob('*.pkl'))\n",
        "    print(f'      Files: {len(files)}')\n",
        "    for f in sorted(files)[:5]:\n",
        "        print(f'      - {f.name}')\n",
        "\n",
        "# Verify project structure\n",
        "print(f'\\nüèóÔ∏è  Project Structure Check:')\n",
        "print(f'   src/: {(PROJECT_DIR / \"src\").exists()}')\n",
        "print(f'   scripts/: {(PROJECT_DIR / \"scripts\").exists()}')\n",
        "print(f'   experiments/: {(PROJECT_DIR / \"experiments\").exists()}')\n",
        "print(f'   src/configs/: {(PROJECT_DIR / \"src\" / \"configs\").exists()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Setup: Clone Project (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "setup"
        ]
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "DRIVE_BASE = Path('/content')  \n",
        "PROJECT_DIR = DRIVE_BASE / 'mhealth-data-privacy'\n",
        "\n",
        "if not PROJECT_DIR.exists():\n",
        "    print('üì• Cloning project...')\n",
        "    os.chdir(DRIVE_BASE)\n",
        "    result = subprocess.run([\n",
        "        'git', 'clone',\n",
        "        'https://github.com/vasco-fernandes21/mhealth-data-privacy.git'\n",
        "    ], capture_output=True, text=True)\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print('‚úÖ Project cloned')\n",
        "    else:\n",
        "        print(f'‚ùå Clone failed: {result.stderr}')\n",
        "else:\n",
        "    print('‚úÖ Project already exists')\n",
        "\n",
        "os.chdir(PROJECT_DIR)\n",
        "print(f'‚úÖ Working directory: {PROJECT_DIR}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Setup: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "setup"
        ]
      },
      "outputs": [],
      "source": [
        "# Install minimal dependencies (most should be in Colab)\n",
        "!pip install -q  opacus scikit-learn pyyaml tqdm -U\n",
        "print('‚úÖ Dependencies installed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Setup: Python Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "setup"
        ]
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Add project to path\n",
        "sys.path.insert(0, str(PROJECT_DIR))\n",
        "\n",
        "# Set seed\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Device\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f'‚úÖ Environment setup:')\n",
        "print(f'   Device: {DEVICE}')\n",
        "print(f'   Seed: {SEED}')\n",
        "if DEVICE == 'cuda':\n",
        "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Configuration: Select Dataset & Scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "config"
        ]
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ‚öôÔ∏è CONFIGURE HERE\n",
        "# ============================================================================\n",
        "\n",
        "# Choose dataset\n",
        "DATASET = 'sleep-edf'  # Options: 'sleep-edf' or 'wesad'\n",
        "\n",
        "# Choose which scenarios to run\n",
        "RUN_SCENARIOS = {\n",
        "    'baseline': True,      # ‚úÖ No privacy\n",
        "    'dp': True,            # ‚úÖ Differential Privacy\n",
        "    'fl': True,            # ‚úÖ Federated Learning\n",
        "    'fl_dp': True          # ‚úÖ FL + DP\n",
        "}\n",
        "\n",
        "# Common parameters\n",
        "TRAIN_PARAMS = {\n",
        "    'epochs': 20,          # Reduced for Colab\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.001,\n",
        "    'seed': SEED,\n",
        "    'device': DEVICE\n",
        "}\n",
        "\n",
        "# DP parameters\n",
        "DP_PARAMS = {\n",
        "    'epsilon': 1.0,\n",
        "    'delta': 1e-5,\n",
        "    'max_grad_norm': 1.0\n",
        "}\n",
        "\n",
        "# FL parameters\n",
        "FL_PARAMS = {\n",
        "    'n_clients': 5,\n",
        "    'local_epochs': 3,\n",
        "    'global_rounds': 20\n",
        "}\n",
        "\n",
        "print('‚öôÔ∏è Configuration:')\n",
        "print(f'   Dataset: {DATASET}')\n",
        "print(f'   Scenarios: {[s for s, v in RUN_SCENARIOS.items() if v]}')\n",
        "print(f'   Epochs: {TRAIN_PARAMS[\"epochs\"]}')\n",
        "print(f'   DP Epsilon: {DP_PARAMS[\"epsilon\"]}')\n",
        "print(f'   FL Clients: {FL_PARAMS[\"n_clients\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training: Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "training"
        ]
      },
      "outputs": [],
      "source": [
        "if RUN_SCENARIOS['baseline']:\n",
        "    print('\\n' + '='*70)\n",
        "    print('üöÄ BASELINE TRAINING')\n",
        "    print('='*70)\n",
        "    \n",
        "    cmd = f\"\"\"python scripts/train_baseline.py \\\n",
        "      --dataset {DATASET} \\\n",
        "      --seed {TRAIN_PARAMS['seed']} \\\n",
        "      --device {TRAIN_PARAMS['device']}\"\"\"\n",
        "    \n",
        "    print(f'Command: {cmd}\\n')\n",
        "    result = os.system(cmd)\n",
        "    \n",
        "    if result == 0:\n",
        "        print('\\n‚úÖ Baseline training completed')\n",
        "    else:\n",
        "        print(f'\\n‚ùå Baseline training failed (code: {result})')\n",
        "else:\n",
        "    print('‚è≠Ô∏è  Baseline training skipped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training: Differential Privacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "training"
        ]
      },
      "outputs": [],
      "source": [
        "if RUN_SCENARIOS['dp']:\n",
        "    print('\\n' + '='*70)\n",
        "    print('üîê DIFFERENTIAL PRIVACY TRAINING')\n",
        "    print('='*70)\n",
        "    \n",
        "    cmd = f\"\"\"python scripts/train_dp.py \\\n",
        "      --dataset {DATASET} \\\n",
        "      --epsilon {DP_PARAMS['epsilon']} \\\n",
        "      --seed {TRAIN_PARAMS['seed']} \\\n",
        "      --device {TRAIN_PARAMS['device']}\"\"\"\n",
        "    \n",
        "    print(f'Command: {cmd}\\n')\n",
        "    result = os.system(cmd)\n",
        "    \n",
        "    if result == 0:\n",
        "        print(f'\\n‚úÖ DP training completed (Œµ={DP_PARAMS[\"epsilon\"]})')\n",
        "    else:\n",
        "        print(f'\\n‚ùå DP training failed (code: {result})')\n",
        "else:\n",
        "    print('‚è≠Ô∏è  DP training skipped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Training: Federated Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "training"
        ]
      },
      "outputs": [],
      "source": [
        "if RUN_SCENARIOS['fl']:\n",
        "    print('\\n' + '='*70)\n",
        "    print('ü§ù FEDERATED LEARNING TRAINING')\n",
        "    print('='*70)\n",
        "    \n",
        "    cmd = f\"\"\"python scripts/train_fl.py \\\n",
        "      --dataset {DATASET} \\\n",
        "      --n_clients {FL_PARAMS['n_clients']} \\\n",
        "      --seed {TRAIN_PARAMS['seed']} \\\n",
        "      --device {TRAIN_PARAMS['device']}\"\"\"\n",
        "    \n",
        "    print(f'Command: {cmd}\\n')\n",
        "    result = os.system(cmd)\n",
        "    \n",
        "    if result == 0:\n",
        "        print(f'\\n‚úÖ FL training completed ({FL_PARAMS[\"n_clients\"]} clients)')\n",
        "    else:\n",
        "        print(f'\\n‚ùå FL training failed (code: {result})')\n",
        "else:\n",
        "    print('‚è≠Ô∏è  FL training skipped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Training: Federated Learning + Differential Privacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "training"
        ]
      },
      "outputs": [],
      "source": [
        "if RUN_SCENARIOS['fl_dp']:\n",
        "    print('\\n' + '='*70)\n",
        "    print('üîí FEDERATED LEARNING + DIFFERENTIAL PRIVACY')\n",
        "    print('='*70)\n",
        "    \n",
        "    cmd = f\"\"\"python scripts/train_fl_dp.py \\\n",
        "      --dataset {DATASET} \\\n",
        "      --n_clients {FL_PARAMS['n_clients']} \\\n",
        "      --epsilon {DP_PARAMS['epsilon']} \\\n",
        "      --seed {TRAIN_PARAMS['seed']} \\\n",
        "      --device {TRAIN_PARAMS['device']}\"\"\"\n",
        "    \n",
        "    print(f'Command: {cmd}\\n')\n",
        "    result = os.system(cmd)\n",
        "    \n",
        "    if result == 0:\n",
        "        print(f'\\n‚úÖ FL+DP training completed')\n",
        "    else:\n",
        "        print(f'\\n‚ùå FL+DP training failed (code: {result})')\n",
        "else:\n",
        "    print('‚è≠Ô∏è  FL+DP training skipped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Results: Load & Compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "analysis"
        ]
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "RESULTS_BASE = Path('./results')\n",
        "\n",
        "print('\\n' + '='*70)\n",
        "print('üìä RESULTS SUMMARY')\n",
        "print('='*70)\n",
        "\n",
        "results_dict = {}\n",
        "\n",
        "# Load results for each scenario\n",
        "scenarios_to_check = [\n",
        "    ('baseline', f'baseline/{DATASET}/results.json'),\n",
        "    ('dp', f'dp/epsilon_1.0/{DATASET}/results.json'),\n",
        "    ('fl', f'fl/{DATASET}/results.json'),\n",
        "    ('fl_dp', f'fl_dp/epsilon_1.0/{DATASET}/results.json')\n",
        "]\n",
        "\n",
        "for scenario_name, result_path in scenarios_to_check:\n",
        "    if not RUN_SCENARIOS.get(scenario_name, True):\n",
        "        continue\n",
        "    \n",
        "    full_path = RESULTS_BASE / result_path\n",
        "    \n",
        "    if full_path.exists():\n",
        "        try:\n",
        "            with open(full_path) as f:\n",
        "                results = json.load(f)\n",
        "            \n",
        "            results_dict[scenario_name] = {\n",
        "                'accuracy': results.get('accuracy', 0),\n",
        "                'f1_score': results.get('f1_score', 0),\n",
        "                'training_time': results.get('training_time_seconds', 0)\n",
        "            }\n",
        "            \n",
        "            print(f'\\n‚úÖ {scenario_name.upper()}')\n",
        "            print(f'   Accuracy: {results_dict[scenario_name][\"accuracy\"]:.4f}')\n",
        "            print(f'   F1-Score: {results_dict[scenario_name][\"f1_score\"]:.4f}')\n",
        "            print(f'   Time: {results_dict[scenario_name][\"training_time\"]:.1f}s')\n",
        "            \n",
        "            if scenario_name == 'dp':\n",
        "                epsilon = results.get('final_epsilon', results.get('epsilon', 'N/A'))\n",
        "                print(f'   Privacy (Œµ): {epsilon}')\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f'‚ùå Error loading {scenario_name}: {e}')\n",
        "    else:\n",
        "        print(f'‚ö†Ô∏è  {scenario_name}: Results file not found at {full_path}')\n",
        "\n",
        "# Create comparison table\n",
        "if results_dict:\n",
        "    df = pd.DataFrame(results_dict).T\n",
        "    print(f'\\n' + '='*70)\n",
        "    print('COMPARISON TABLE')\n",
        "    print('='*70)\n",
        "    print(df.round(4).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Results: Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "analysis"
        ]
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "if results_dict:\n",
        "    sns.set_style('whitegrid')\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Accuracy comparison\n",
        "    scenarios = list(results_dict.keys())\n",
        "    accuracies = [results_dict[s]['accuracy'] for s in scenarios]\n",
        "    \n",
        "    colors = ['green', 'orange', 'blue', 'red']\n",
        "    bars = axes[0].bar(scenarios, accuracies, color=colors[:len(scenarios)], \n",
        "                        alpha=0.7, edgecolor='black', linewidth=2)\n",
        "    axes[0].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "    axes[0].set_title(f'{DATASET.upper()} - Accuracy Comparison', fontsize=13, fontweight='bold')\n",
        "    axes[0].set_ylim([0.5, 1.0])\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    for bar, acc in zip(bars, accuracies):\n",
        "        height = bar.get_height()\n",
        "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{acc:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    # F1-Score comparison\n",
        "    f1_scores = [results_dict[s]['f1_score'] for s in scenarios]\n",
        "    bars2 = axes[1].bar(scenarios, f1_scores, color=colors[:len(scenarios)], \n",
        "                         alpha=0.7, edgecolor='black', linewidth=2)\n",
        "    axes[1].set_ylabel('F1-Score', fontsize=12, fontweight='bold')\n",
        "    axes[1].set_title(f'{DATASET.upper()} - F1-Score Comparison', fontsize=13, fontweight='bold')\n",
        "    axes[1].set_ylim([0.5, 1.0])\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    for bar, f1 in zip(bars2, f1_scores):\n",
        "        height = bar.get_height()\n",
        "        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{f1:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results_comparison.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print('‚úÖ Visualization saved as results_comparison.png')\n",
        "else:\n",
        "    print('‚ö†Ô∏è  No results to visualize')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "export"
        ]
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print('\\n' + '='*70)\n",
        "print('üì• EXPORTING RESULTS')\n",
        "print('='*70)\n",
        "\n",
        "# Create zip with results\n",
        "if RESULTS_BASE.exists():\n",
        "    print('\\nCreating results archive...')\n",
        "    shutil.make_archive('mhealth_results', 'zip', RESULTS_BASE)\n",
        "    print('‚úÖ Archive created: mhealth_results.zip')\n",
        "    \n",
        "    # Download\n",
        "    files.download('mhealth_results.zip')\n",
        "    print('‚úÖ Downloaded to your computer!')\n",
        "else:\n",
        "    print('‚ö†Ô∏è  No results directory found')\n",
        "\n",
        "# Also download visualization if exists\n",
        "if os.path.exists('results_comparison.png'):\n",
        "    files.download('results_comparison.png')\n",
        "    print('‚úÖ Downloaded visualization!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "summary"
        ]
      },
      "outputs": [],
      "source": [
        "print('\\n' + '='*70)\n",
        "print('‚úÖ PIPELINE COMPLETE')\n",
        "print('='*70)\n",
        "\n",
        "print(f'\\nüìä Execution Summary:')\n",
        "print(f'   Dataset: {DATASET}')\n",
        "print(f'   Scenarios run: {[s for s, v in RUN_SCENARIOS.items() if v]}')\n",
        "print(f'   Epochs: {TRAIN_PARAMS[\"epochs\"]}')\n",
        "print(f'   Results scenarios: {list(results_dict.keys()) if results_dict else \"None\"}')\n",
        "\n",
        "if results_dict:\n",
        "    baseline_acc = results_dict.get('baseline', {}).get('accuracy', 0)\n",
        "    dp_acc = results_dict.get('dp', {}).get('accuracy', 0)\n",
        "    \n",
        "    if baseline_acc > 0 and dp_acc > 0:\n",
        "        drop = (baseline_acc - dp_acc) * 100\n",
        "        print(f'\\nüìà Privacy-Utility Tradeoff:')\n",
        "        print(f'   Baseline Accuracy: {baseline_acc:.4f}')\n",
        "        print(f'   DP Accuracy (Œµ=1.0): {dp_acc:.4f}')\n",
        "        print(f'   Accuracy Drop: {drop:.2f}%')\n",
        "\n",
        "print(f'\\nüìÅ Results Location:')\n",
        "print(f'   Local: {RESULTS_BASE}')\n",
        "print(f'   Drive: {DRIVE_BASE}/mhealth-privacy/results')\n",
        "\n",
        "print(f'\\nüöÄ Next Steps:')\n",
        "print(f'   1. Analyze results in results_comparison.png')\n",
        "print(f'   2. Run with different epsilon values: [0.5, 1.0, 2.0, 5.0]')\n",
        "print(f'   3. Vary n_clients for FL experiments')\n",
        "print(f'   4. Generate paper plots and tables')\n",
        "\n",
        "print('\\n' + '='*70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
