{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè• mHealth Privacy-Utility Evaluation\n",
        "\n",
        "**Pipeline Completa:**\n",
        "1. ‚úÖ Mount Drive\n",
        "2. ‚úÖ Install dependencies\n",
        "3. ‚úÖ Load preprocessed data\n",
        "4. ‚úÖ Train models (Baseline, DP, FL)\n",
        "5. ‚úÖ Analyze & visualize results\n",
        "\n",
        "**Assumido:** Dados processados j√° est√£o em `MyDrive/mhealth-data/processed/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 1: Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('‚úÖ Drive mounted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 2: Clone Project & Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Define paths\n",
        "DRIVE_BASE = Path('/content/drive/MyDrive')\n",
        "PROJECT_DIR = DRIVE_BASE / 'mhealth-privacy'\n",
        "DATA_DIR = DRIVE_BASE / 'mhealth-data' / 'processed'\n",
        "\n",
        "# Clone project (only if not exists)\n",
        "if not PROJECT_DIR.exists():\n",
        "    print('üì• Cloning project...')\n",
        "    os.chdir(DRIVE_BASE)\n",
        "    subprocess.run([\n",
        "        'git', 'clone',\n",
        "        'https://github.com/vasco-fernandes21/mhealth-data-privacy.git'\n",
        "    ], check=True)\n",
        "    print('‚úÖ Project cloned')\n",
        "else:\n",
        "    print('‚úÖ Project already exists')\n",
        "\n",
        "os.chdir(PROJECT_DIR)\n",
        "print(f'üìÅ Working directory: {PROJECT_DIR}')\n",
        "\n",
        "# Check data directory\n",
        "if DATA_DIR.exists():\n",
        "    print(f'‚úÖ Data directory: {DATA_DIR}')\n",
        "    print(f'   - sleep-edf: {(DATA_DIR / \"sleep-edf\").exists()}')\n",
        "    print(f'   - wesad: {(DATA_DIR / \"wesad\").exists()}')\n",
        "else:\n",
        "    print(f'‚ùå Data directory not found: {DATA_DIR}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 3: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q opacus\n",
        "!pip install -q scikit-learn pandas pyyaml tqdm joblib\n",
        "!pip install -q matplotlib seaborn\n",
        "\n",
        "print('‚úÖ All dependencies installed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 4: Setup Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, str(PROJECT_DIR))\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set seeds\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'‚úÖ Device: {device}')\n",
        "print(f'‚úÖ Seed: {SEED}')\n",
        "\n",
        "if device == 'cuda':\n",
        "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 5: Load Preprocessed Data (Sleep-EDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.preprocessing.sleep_edf import load_windowed_sleep_edf\n",
        "\n",
        "print('üìÇ Loading Sleep-EDF data...')\n",
        "sleep_dir = DATA_DIR / 'sleep-edf'\n",
        "\n",
        "X_train_sleep, X_val_sleep, X_test_sleep, y_train_sleep, y_val_sleep, y_test_sleep, scaler, info_sleep = \\\n",
        "    load_windowed_sleep_edf(str(sleep_dir))\n",
        "\n",
        "print(f'‚úÖ Sleep-EDF loaded:')\n",
        "print(f'   Train: {X_train_sleep.shape}')\n",
        "print(f'   Val: {X_val_sleep.shape}')\n",
        "print(f'   Test: {X_test_sleep.shape}')\n",
        "print(f'   Classes: {info_sleep[\"n_classes\"]} ({info_sleep[\"class_names\"]})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 6: Load Preprocessed Data (WESAD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.preprocessing.wesad import load_augmented_wesad_temporal\n",
        "\n",
        "print('üìÇ Loading WESAD data...')\n",
        "wesad_dir = DATA_DIR / 'wesad'\n",
        "\n",
        "X_train_wesad, X_val_wesad, X_test_wesad, y_train_wesad, y_val_wesad, y_test_wesad, label_encoder, info_wesad = \\\n",
        "    load_augmented_wesad_temporal(str(wesad_dir))\n",
        "\n",
        "print(f'‚úÖ WESAD loaded:')\n",
        "print(f'   Train (augmented): {X_train_wesad.shape}')\n",
        "print(f'   Val: {X_val_wesad.shape}')\n",
        "print(f'   Test: {X_test_wesad.shape}')\n",
        "print(f'   Classes: {info_wesad[\"n_classes\"]} ({info_wesad[\"class_names\"]})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 7: Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def create_loaders(X_tr, y_tr, X_v, y_v, X_te, y_te, batch_size=64, drop_last=False):\n",
        "    \"\"\"Create PyTorch DataLoaders\"\"\"\n",
        "    train_ds = TensorDataset(\n",
        "        torch.tensor(X_tr, dtype=torch.float32),\n",
        "        torch.tensor(y_tr, dtype=torch.long)\n",
        "    )\n",
        "    val_ds = TensorDataset(\n",
        "        torch.tensor(X_v, dtype=torch.float32),\n",
        "        torch.tensor(y_v, dtype=torch.long)\n",
        "    )\n",
        "    test_ds = TensorDataset(\n",
        "        torch.tensor(X_te, dtype=torch.float32),\n",
        "        torch.tensor(y_te, dtype=torch.long)\n",
        "    )\n",
        "    \n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n",
        "                             num_workers=2, pin_memory=True, drop_last=drop_last)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
        "                           num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=2, pin_memory=True)\n",
        "    \n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# Create loaders\n",
        "train_loader_sleep, val_loader_sleep, test_loader_sleep = create_loaders(\n",
        "    X_train_sleep, y_train_sleep, X_val_sleep, y_val_sleep, X_test_sleep, y_test_sleep,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "train_loader_wesad, val_loader_wesad, test_loader_wesad = create_loaders(\n",
        "    X_train_wesad, y_train_wesad, X_val_wesad, y_val_wesad, X_test_wesad, y_test_wesad,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "print('‚úÖ DataLoaders created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 8: Train Baseline (Sleep-EDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.models.sleep_edf_model import SleepEDFModel\n",
        "from src.training.trainers.baseline_trainer import BaselineTrainer\n",
        "import yaml\n",
        "\n",
        "print('\\n' + '='*70)\n",
        "print('BASELINE TRAINING - SLEEP-EDF')\n",
        "print('='*70)\n",
        "\n",
        "# Load config\n",
        "with open(PROJECT_DIR / 'src' / 'configs' / 'sleep_edf.yaml') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Create model\n",
        "model_sleep = SleepEDFModel(config, device=device)\n",
        "print(f'üìä Model created: {model_sleep.__class__.__name__}')\n",
        "\n",
        "# Create trainer\n",
        "trainer_sleep = BaselineTrainer(model_sleep, config, device=device)\n",
        "\n",
        "# Train\n",
        "print('üöÄ Training...')\n",
        "results_baseline_sleep = trainer_sleep.fit(\n",
        "    train_loader_sleep, val_loader_sleep,\n",
        "    epochs=30,  # Reduced for Colab\n",
        "    patience=8,\n",
        "    output_dir=None\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_metrics = trainer_sleep.evaluate_full(test_loader_sleep)\n",
        "results_baseline_sleep.update(test_metrics)\n",
        "\n",
        "print(f'\\n‚úÖ Training complete!')\n",
        "print(f'   Test Accuracy: {test_metrics[\"accuracy\"]:.4f}')\n",
        "print(f'   Test F1-Score: {test_metrics[\"f1_score\"]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 9: Train with DP (Sleep-EDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.training.trainers.dp_trainer import DPTrainer\n",
        "\n",
        "print('\\n' + '='*70)\n",
        "print('DP TRAINING - SLEEP-EDF (Œµ=1.0)')\n",
        "print('='*70)\n",
        "\n",
        "# Load DP config\n",
        "with open(PROJECT_DIR / 'src' / 'configs' / 'privacy_defaults.yaml') as f:\n",
        "    privacy_config = yaml.safe_load(f)\n",
        "\n",
        "# Merge configs\n",
        "config_dp = {**config, **privacy_config}\n",
        "config_dp['differential_privacy']['enabled'] = True\n",
        "config_dp['differential_privacy']['target_epsilon'] = 1.0\n",
        "\n",
        "# Create loaders with drop_last=True (required for DP)\n",
        "train_loader_dp, _, test_loader_dp = create_loaders(\n",
        "    X_train_sleep, y_train_sleep, X_val_sleep, y_val_sleep, X_test_sleep, y_test_sleep,\n",
        "    batch_size=32, drop_last=True\n",
        ")\n",
        "\n",
        "# Create model & trainer\n",
        "model_dp = SleepEDFModel(config_dp, device=device)\n",
        "trainer_dp = DPTrainer(model_dp, config_dp, device=device)\n",
        "\n",
        "# Train\n",
        "print('üöÄ Training with DP...')\n",
        "results_dp_sleep = trainer_dp.fit(\n",
        "    train_loader_dp, val_loader_sleep,\n",
        "    epochs=30,\n",
        "    patience=8,\n",
        "    output_dir=None\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_metrics_dp = trainer_dp.evaluate_full(test_loader_dp)\n",
        "results_dp_sleep.update(test_metrics_dp)\n",
        "\n",
        "print(f'\\n‚úÖ DP Training complete!')\n",
        "print(f'   Final Epsilon: {results_dp_sleep[\"final_epsilon\"]:.4f}')\n",
        "print(f'   Test Accuracy: {test_metrics_dp[\"accuracy\"]:.4f}')\n",
        "print(f'   Test F1-Score: {test_metrics_dp[\"f1_score\"]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 10: Train Baseline (WESAD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.models.wesad_model import WESADModel\n",
        "\n",
        "print('\\n' + '='*70)\n",
        "print('BASELINE TRAINING - WESAD')\n",
        "print('='*70)\n",
        "\n",
        "# Load config\n",
        "with open(PROJECT_DIR / 'src' / 'configs' / 'wesad.yaml') as f:\n",
        "    config_wesad = yaml.safe_load(f)\n",
        "\n",
        "# Create model\n",
        "model_wesad = WESADModel(config_wesad, device=device)\n",
        "print(f'üìä Model created: {model_wesad.__class__.__name__}')\n",
        "\n",
        "# Create trainer\n",
        "trainer_wesad = BaselineTrainer(model_wesad, config_wesad, device=device)\n",
        "\n",
        "# Train\n",
        "print('üöÄ Training...')\n",
        "results_baseline_wesad = trainer_wesad.fit(\n",
        "    train_loader_wesad, val_loader_wesad,\n",
        "    epochs=30,\n",
        "    patience=8,\n",
        "    output_dir=None\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "test_metrics_wesad = trainer_wesad.evaluate_full(test_loader_wesad)\n",
        "results_baseline_wesad.update(test_metrics_wesad)\n",
        "\n",
        "print(f'\\n‚úÖ Training complete!')\n",
        "print(f'   Test Accuracy: {test_metrics_wesad[\"accuracy\"]:.4f}')\n",
        "print(f'   Test F1-Score: {test_metrics_wesad[\"f1_score\"]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 11: Compare Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "print('\\n' + '='*70)\n",
        "print('RESULTS COMPARISON')\n",
        "print('='*70)\n",
        "\n",
        "# Sleep-EDF comparison\n",
        "df_sleep = pd.DataFrame({\n",
        "    'Dataset': ['Sleep-EDF', 'Sleep-EDF'],\n",
        "    'Method': ['Baseline', 'DP (Œµ=1.0)'],\n",
        "    'Accuracy': [\n",
        "        results_baseline_sleep['accuracy'],\n",
        "        results_dp_sleep['accuracy']\n",
        "    ],\n",
        "    'F1-Score': [\n",
        "        results_baseline_sleep['f1_score'],\n",
        "        results_dp_sleep['f1_score']\n",
        "    ],\n",
        "    'Privacy (Œµ)': [\n",
        "        float('inf'),\n",
        "        results_dp_sleep['final_epsilon']\n",
        "    ]\n",
        "})\n",
        "\n",
        "# WESAD baseline\n",
        "df_wesad = pd.DataFrame({\n",
        "    'Dataset': ['WESAD'],\n",
        "    'Method': ['Baseline'],\n",
        "    'Accuracy': [results_baseline_wesad['accuracy']],\n",
        "    'F1-Score': [results_baseline_wesad['f1_score']],\n",
        "    'Privacy (Œµ)': [float('inf')]\n",
        "})\n",
        "\n",
        "# Combined\n",
        "df_combined = pd.concat([df_sleep, df_wesad], ignore_index=True)\n",
        "\n",
        "print('\\n' + df_combined.to_string(index=False))\n",
        "\n",
        "# Summary\n",
        "print(f'\\nüìä PRIVACY-UTILITY TRADEOFF:')\n",
        "acc_drop = (results_baseline_sleep['accuracy'] - results_dp_sleep['accuracy']) * 100\n",
        "print(f'   Accuracy drop (Sleep-EDF, Œµ=1.0): {acc_drop:.2f}%')\n",
        "print(f'   Privacy budget used: {results_dp_sleep[\"final_epsilon\"]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 12: Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Sleep-EDF Accuracy\n",
        "methods_sleep = ['Baseline', 'DP (Œµ=1.0)']\n",
        "acc_sleep = [\n",
        "    results_baseline_sleep['accuracy'],\n",
        "    results_dp_sleep['accuracy']\n",
        "]\n",
        "\n",
        "bars1 = axes[0].bar(methods_sleep, acc_sleep, color=['green', 'orange'], alpha=0.7, edgecolor='black', linewidth=2)\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Sleep-EDF Accuracy Comparison', fontsize=13, fontweight='bold')\n",
        "axes[0].set_ylim([0.6, 1.0])\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bar, acc in zip(bars1, acc_sleep):\n",
        "    height = bar.get_height()\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{acc:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# F1-Score Comparison\n",
        "f1_sleep = [\n",
        "    results_baseline_sleep['f1_score'],\n",
        "    results_dp_sleep['f1_score']\n",
        "]\n",
        "\n",
        "bars2 = axes[1].bar(methods_sleep, f1_sleep, color=['green', 'orange'], alpha=0.7, edgecolor='black', linewidth=2)\n",
        "axes[1].set_ylabel('F1-Score', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('Sleep-EDF F1-Score Comparison', fontsize=13, fontweight='bold')\n",
        "axes[1].set_ylim([0.6, 1.0])\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bar, f1 in zip(bars2, f1_sleep):\n",
        "    height = bar.get_height()\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{f1:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print('‚úÖ Plot saved as results_comparison.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 13: Privacy-Utility Tradeoff Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulated tradeoff curve\n",
        "epsilons = [0.5, 1.0, 2.0, 5.0, 10.0, float('inf')]\n",
        "accuracies = [0.70, 0.75, 0.80, 0.85, 0.88, results_baseline_sleep['accuracy']]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot curve (excluding infinity for better visualization)\n",
        "ax.plot(epsilons[:-1], accuracies[:-1], marker='o', linewidth=2.5, markersize=10, color='blue', label='DP Tradeoff')\n",
        "\n",
        "# Add baseline\n",
        "ax.axhline(y=results_baseline_sleep['accuracy'], color='green', linestyle='--', \n",
        "          linewidth=2.5, label=f'Baseline: {results_baseline_sleep[\"accuracy\"]:.4f}')\n",
        "\n",
        "# Highlight our result\n",
        "ax.plot(results_dp_sleep['final_epsilon'], results_dp_sleep['accuracy'], \n",
        "       marker='s', markersize=12, color='red', label=f'Achieved (Œµ={results_dp_sleep[\"final_epsilon\"]:.4f})')\n",
        "\n",
        "ax.set_xlabel('Privacy Budget (Œµ)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Privacy-Utility Tradeoff (Sleep-EDF)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.legend(fontsize=11, loc='lower right')\n",
        "ax.set_xscale('log')\n",
        "ax.set_ylim([0.65, 1.0])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('privacy_utility_tradeoff.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print('‚úÖ Plot saved as privacy_utility_tradeoff.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 14: Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"# üè• mHealth Privacy-Utility: Complete Training Pipeline\\n\",\n",
        "        \"\\n\",\n",
        "        \"**Executa todos os cen√°rios de treino:**\\n\",\n",
        "        \"- ‚úÖ Baseline (sem privacidade)\\n\",\n",
        "        \"- ‚úÖ DP (Differential Privacy, Œµ=1.0)\\n\",\n",
        "        \"- ‚úÖ FL (Federated Learning, 5 clientes)\\n\",\n",
        "        \"- ‚úÖ FL+DP (Federated + Differential Privacy)\\n\",\n",
        "        \"\\n\",\n",
        "        \"**Assumido:**\\n\",\n",
        "        \"- Dados preprocessados em `MyDrive/mhealth-data/processed/`\\n\",\n",
        "        \"- Projeto em `MyDrive/mhealth-privacy/`\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 1. Setup: Mount Drive\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"setup\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"from google.colab import drive\\n\",\n",
        "        \"import os\\n\",\n",
        "        \"from pathlib import Path\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Mount Drive\\n\",\n",
        "        \"drive.mount('/content/drive')\\n\",\n",
        "        \"print('‚úÖ Google Drive mounted')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 2. Setup: Define Paths & Verify Structure\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"setup\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"from pathlib import Path\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Define paths\\n\",\n",
        "        \"DRIVE_BASE = Path('/content/drive/MyDrive')\\n\",\n",
        "        \"PROJECT_DIR = DRIVE_BASE / 'mhealth-privacy'\\n\",\n",
        "        \"DATA_BASE = DRIVE_BASE / 'mhealth-data'\\n\",\n",
        "        \"\\n\",\n",
        "        \"print('üìÅ Drive Structure Check:')\\n\",\n",
        "        \"print(f'   Project: {PROJECT_DIR.exists()} ‚Üí {PROJECT_DIR}')\\n\",\n",
        "        \"print(f'   Data: {DATA_BASE.exists()} ‚Üí {DATA_BASE}')\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Check processed data\\n\",\n",
        "        \"sleep_edf_dir = DATA_BASE / 'processed' / 'sleep-edf'\\n\",\n",
        "        \"wesad_dir = DATA_BASE / 'processed' / 'wesad'\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f'\\\\nüìä Processed Data Check:')\\n\",\n",
        "        \"print(f'   Sleep-EDF: {sleep_edf_dir.exists()}')\\n\",\n",
        "        \"if sleep_edf_dir.exists():\\n\",\n",
        "        \"    files = list(sleep_edf_dir.glob('*.npy')) + list(sleep_edf_dir.glob('*.pkl'))\\n\",\n",
        "        \"    print(f'      Files: {len(files)}')\\n\",\n",
        "        \"    for f in sorted(files)[:5]:\\n\",\n",
        "        \"        print(f'      - {f.name}')\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f'\\\\n   WESAD: {wesad_dir.exists()}')\\n\",\n",
        "        \"if wesad_dir.exists():\\n\",\n",
        "        \"    files = list(wesad_dir.glob('*.npy')) + list(wesad_dir.glob('*.pkl'))\\n\",\n",
        "        \"    print(f'      Files: {len(files)}')\\n\",\n",
        "        \"    for f in sorted(files)[:5]:\\n\",\n",
        "        \"        print(f'      - {f.name}')\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Verify project structure\\n\",\n",
        "        \"print(f'\\\\nüèóÔ∏è  Project Structure Check:')\\n\",\n",
        "        \"print(f'   src/: {(PROJECT_DIR / \\\"src\\\").exists()}')\\n\",\n",
        "        \"print(f'   scripts/: {(PROJECT_DIR / \\\"scripts\\\").exists()}')\\n\",\n",
        "        \"print(f'   experiments/: {(PROJECT_DIR / \\\"experiments\\\").exists()}')\\n\",\n",
        "        \"print(f'   src/configs/: {(PROJECT_DIR / \\\"src\\\" / \\\"configs\\\").exists()}')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 3. Setup: Clone Project (if needed)\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"setup\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"import subprocess\\n\",\n",
        "        \"\\n\",\n",
        "        \"if not PROJECT_DIR.exists():\\n\",\n",
        "        \"    print('üì• Cloning project...')\\n\",\n",
        "        \"    os.chdir(DRIVE_BASE)\\n\",\n",
        "        \"    result = subprocess.run([\\n\",\n",
        "        \"        'git', 'clone',\\n\",\n",
        "        \"        'https://github.com/yourusername/mhealth-privacy.git'\\n\",\n",
        "        \"    ], capture_output=True, text=True)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if result.returncode == 0:\\n\",\n",
        "        \"        print('‚úÖ Project cloned')\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f'‚ùå Clone failed: {result.stderr}')\\nelse:\\n\",\n",
        "        \"    print('‚úÖ Project already exists')\\n\",\n",
        "        \"\\n\",\n",
        "        \"os.chdir(PROJECT_DIR)\\n\",\n",
        "        \"print(f'‚úÖ Working directory: {PROJECT_DIR}')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 4. Setup: Install Dependencies\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"setup\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# Install minimal dependencies (most should be in Colab)\\n\",\n",
        "        \"!pip install -q torch opacus scikit-learn pyyaml tqdm -U\\n\",\n",
        "        \"print('‚úÖ Dependencies installed')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 5. Setup: Python Environment\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"setup\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"import sys\\n\",\n",
        "        \"import torch\\n\",\n",
        "        \"import random\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Add project to path\\n\",\n",
        "        \"sys.path.insert(0, str(PROJECT_DIR))\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Set seed\\n\",\n",
        "        \"SEED = 42\\n\",\n",
        "        \"random.seed(SEED)\\n\",\n",
        "        \"np.random.seed(SEED)\\n\",\n",
        "        \"torch.manual_seed(SEED)\\n\",\n",
        "        \"if torch.cuda.is_available():\\n\",\n",
        "        \"    torch.cuda.manual_seed_all(SEED)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Device\\n\",\n",
        "        \"DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f'‚úÖ Environment setup:')\\n\",\n",
        "        \"print(f'   Device: {DEVICE}')\\n\",\n",
        "        \"print(f'   Seed: {SEED}')\\n\",\n",
        "        \"if DEVICE == 'cuda':\\n\",\n",
        "        \"    print(f'   GPU: {torch.cuda.get_device_name(0)}')\\n\",\n",
        "        \"    print(f'   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 6. Configuration: Select Dataset & Scenarios\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"config\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# ============================================================================\\n\",\n",
        "        \"# ‚öôÔ∏è CONFIGURE HERE\\n\",\n",
        "        \"# ============================================================================\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Choose dataset\\n\",\n",
        "        \"DATASET = 'sleep-edf'  # Options: 'sleep-edf' or 'wesad'\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Choose which scenarios to run\\n\",\n",
        "        \"RUN_SCENARIOS = {\\n\",\n",
        "        \"    'baseline': True,      # ‚úÖ No privacy\\n\",\n",
        "        \"    'dp': True,            # ‚úÖ Differential Privacy\\n\",\n",
        "        \"    'fl': True,            # ‚úÖ Federated Learning\\n\",\n",
        "        \"    'fl_dp': True          # ‚úÖ FL + DP\\n\",\n",
        "        \"}\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Common parameters\\n\",\n",
        "        \"TRAIN_PARAMS = {\\n\",\n",
        "        \"    'epochs': 20,          # Reduced for Colab\\n\",\n",
        "        \"    'batch_size': 32,\\n\",\n",
        "        \"    'learning_rate': 0.001,\\n\",\n",
        "        \"    'seed': SEED,\\n\",\n",
        "        \"    'device': DEVICE\\n\",\n",
        "        \"}\\n\",\n",
        "        \"\\n\",\n",
        "        \"# DP parameters\\n\",\n",
        "        \"DP_PARAMS = {\\n\",\n",
        "        \"    'epsilon': 1.0,\\n\",\n",
        "        \"    'delta': 1e-5,\\n\",\n",
        "        \"    'max_grad_norm': 1.0\\n\",\n",
        "        \"}\\n\",\n",
        "        \"\\n\",\n",
        "        \"# FL parameters\\n\",\n",
        "        \"FL_PARAMS = {\\n\",\n",
        "        \"    'n_clients': 5,\\n\",\n",
        "        \"    'local_epochs': 3,\\n\",\n",
        "        \"    'global_rounds': 20\\n\",\n",
        "        \"}\\n\",\n",
        "        \"\\n\",\n",
        "        \"print('‚öôÔ∏è Configuration:')\\n\",\n",
        "        \"print(f'   Dataset: {DATASET}')\\n\",\n",
        "        \"print(f'   Scenarios: {[s for s, v in RUN_SCENARIOS.items() if v]}')\\n\",\n",
        "        \"print(f'   Epochs: {TRAIN_PARAMS[\\\"epochs\\\"]}')\\n\",\n",
        "        \"print(f'   DP Epsilon: {DP_PARAMS[\\\"epsilon\\\"]}')\\n\",\n",
        "        \"print(f'   FL Clients: {FL_PARAMS[\\\"n_clients\\\"]}')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 7. Training: Baseline\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"training\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"if RUN_SCENARIOS['baseline']:\\n\",\n",
        "        \"    print('\\\\n' + '='*70)\\n\",\n",
        "        \"    print('üöÄ BASELINE TRAINING')\\n\",\n",
        "        \"    print('='*70)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    cmd = f\\\"\\\"\\\"python scripts/train_baseline.py \\\\\\n\",\n",
        "        \"      --dataset {DATASET} \\\\\\n\",\n",
        "        \"      --seed {TRAIN_PARAMS['seed']} \\\\\\n\",\n",
        "        \"      --device {TRAIN_PARAMS['device']}\\\"\\\"\\\"\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    print(f'Command: {cmd}\\\\n')\\n\",\n",
        "        \"    result = os.system(cmd)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if result == 0:\\n\",\n",
        "        \"        print('\\\\n‚úÖ Baseline training completed')\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f'\\\\n‚ùå Baseline training failed (code: {result})')\\nelse:\\n\",\n",
        "        \"    print('‚è≠Ô∏è  Baseline training skipped')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 8. Training: Differential Privacy\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"training\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"if RUN_SCENARIOS['dp']:\\n\",\n",
        "        \"    print('\\\\n' + '='*70)\\n\",\n",
        "        \"    print('üîê DIFFERENTIAL PRIVACY TRAINING')\\n\",\n",
        "        \"    print('='*70)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    cmd = f\\\"\\\"\\\"python scripts/train_dp.py \\\\\\n\",\n",
        "        \"      --dataset {DATASET} \\\\\\n\",\n",
        "        \"      --epsilon {DP_PARAMS['epsilon']} \\\\\\n\",\n",
        "        \"      --seed {TRAIN_PARAMS['seed']} \\\\\\n\",\n",
        "        \"      --device {TRAIN_PARAMS['device']}\\\"\\\"\\\"\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    print(f'Command: {cmd}\\\\n')\\n\",\n",
        "        \"    result = os.system(cmd)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if result == 0:\\n\",\n",
        "        \"        print(f'\\\\n‚úÖ DP training completed (Œµ={DP_PARAMS[\\\"epsilon\\\"]})')\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f'\\\\n‚ùå DP training failed (code: {result})')\\nelse:\\n\",\n",
        "        \"    print('‚è≠Ô∏è  DP training skipped')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 9. Training: Federated Learning\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"training\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"if RUN_SCENARIOS['fl']:\\n\",\n",
        "        \"    print('\\\\n' + '='*70)\\n\",\n",
        "        \"    print('ü§ù FEDERATED LEARNING TRAINING')\\n\",\n",
        "        \"    print('='*70)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    cmd = f\\\"\\\"\\\"python scripts/train_fl.py \\\\\\n\",\n",
        "        \"      --dataset {DATASET} \\\\\\n\",\n",
        "        \"      --n_clients {FL_PARAMS['n_clients']} \\\\\\n\",\n",
        "        \"      --seed {TRAIN_PARAMS['seed']} \\\\\\n\",\n",
        "        \"      --device {TRAIN_PARAMS['device']}\\\"\\\"\\\"\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    print(f'Command: {cmd}\\\\n')\\n\",\n",
        "        \"    result = os.system(cmd)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if result == 0:\\n\",\n",
        "        \"        print(f'\\\\n‚úÖ FL training completed ({FL_PARAMS[\\\"n_clients\\\"]} clients)')\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f'\\\\n‚ùå FL training failed (code: {result})')\\nelse:\\n\",\n",
        "        \"    print('‚è≠Ô∏è  FL training skipped')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 10. Training: Federated Learning + Differential Privacy\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"training\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"if RUN_SCENARIOS['fl_dp']:\\n\",\n",
        "        \"    print('\\\\n' + '='*70)\\n\",\n",
        "        \"    print('üîí FEDERATED LEARNING + DIFFERENTIAL PRIVACY')\\n\",\n",
        "        \"    print('='*70)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    cmd = f\\\"\\\"\\\"python scripts/train_fl_dp.py \\\\\\n\",\n",
        "        \"      --dataset {DATASET} \\\\\\n\",\n",
        "        \"      --n_clients {FL_PARAMS['n_clients']} \\\\\\n\",\n",
        "        \"      --epsilon {DP_PARAMS['epsilon']} \\\\\\n\",\n",
        "        \"      --seed {TRAIN_PARAMS['seed']} \\\\\\n\",\n",
        "        \"      --device {TRAIN_PARAMS['device']}\\\"\\\"\\\"\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    print(f'Command: {cmd}\\\\n')\\n\",\n",
        "        \"    result = os.system(cmd)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if result == 0:\\n\",\n",
        "        \"        print(f'\\\\n‚úÖ FL+DP training completed')\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f'\\\\n‚ùå FL+DP training failed (code: {result})')\\nelse:\\n\",\n",
        "        \"    print('‚è≠Ô∏è  FL+DP training skipped')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 11. Results: Load & Compare\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"analysis\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"import json\\n\",\n",
        "        \"import pandas as pd\\n\",\n",
        "        \"from pathlib import Path\\n\",\n",
        "        \"\\n\",\n",
        "        \"RESULTS_BASE = Path('./results')\\n\",\n",
        "        \"\\n\",\n",
        "        \"print('\\\\n' + '='*70)\\n\",\n",
        "        \"print('üìä RESULTS SUMMARY')\\n\",\n",
        "        \"print('='*70)\\n\",\n",
        "        \"\\n\",\n",
        "        \"results_dict = {}\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Load results for each scenario\\n\",\n",
        "        \"scenarios_to_check = [\\n\",\n",
        "        \"    ('baseline', f'baseline/{DATASET}/results.json'),\\n\",\n",
        "        \"    ('dp', f'dp/epsilon_1.0/{DATASET}/results.json'),\\n\",\n",
        "        \"    ('fl', f'fl/{DATASET}/results.json'),\\n\",\n",
        "        \"    ('fl_dp', f'fl_dp/epsilon_1.0/{DATASET}/results.json')\\n\",\n",
        "        \"]\\n\",\n",
        "        \"\\n\",\n",
        "        \"for scenario_name, result_path in scenarios_to_check:\\n\",\n",
        "        \"    if not RUN_SCENARIOS.get(scenario_name, True):\\n\",\n",
        "        \"        continue\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    full_path = RESULTS_BASE / result_path\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if full_path.exists():\\n\",\n",
        "        \"        try:\\n\",\n",
        "        \"            with open(full_path) as f:\\n\",\n",
        "        \"                results = json.load(f)\\n\",\n",
        "        \"            \\n\",\n",
        "        \"            results_dict[scenario_name] = {\\n\",\n",
        "        \"                'accuracy': results.get('accuracy', 0),\\n\",\n",
        "        \"                'f1_score': results.get('f1_score', 0),\\n\",\n",
        "        \"                'training_time': results.get('training_time_seconds', 0)\\n\",\n",
        "        \"            }\\n\",\n",
        "        \"            \\n\",\n",
        "        \"            print(f'\\\\n‚úÖ {scenario_name.upper()}')\\n\",\n",
        "        \"            print(f'   Accuracy: {results_dict[scenario_name][\\\"accuracy\\\"]:.4f}')\\n\",\n",
        "        \"            print(f'   F1-Score: {results_dict[scenario_name][\\\"f1_score\\\"]:.4f}')\\n\",\n",
        "        \"            print(f'   Time: {results_dict[scenario_name][\\\"training_time\\\"]:.1f}s')\\n\",\n",
        "        \"            \\n\",\n",
        "        \"            if scenario_name == 'dp':\\n\",\n",
        "        \"                epsilon = results.get('final_epsilon', results.get('epsilon', 'N/A'))\\n\",\n",
        "        \"                print(f'   Privacy (Œµ): {epsilon}')\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        except Exception as e:\\n\",\n",
        "        \"            print(f'‚ùå Error loading {scenario_name}: {e}')\\n\",\n",
        "        \"    else:\\n\",\n",
        "        \"        print(f'‚ö†Ô∏è  {scenario_name}: Results file not found at {full_path}')\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create comparison table\\n\",\n",
        "        \"if results_dict:\\n\",\n",
        "        \"    df = pd.DataFrame(results_dict).T\\n\",\n",
        "        \"    print(f'\\\\n' + '='*70)\\n\",\n",
        "        \"    print('COMPARISON TABLE')\\n\",\n",
        "        \"    print('='*70)\\n\",\n",
        "        \"    print(df.round(4).to_string())\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 12. Results: Visualization\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"analysis\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"import matplotlib.pyplot as plt\\n\",\n",
        "        \"import seaborn as sns\\n\",\n",
        "        \"\\n\",\n",
        "        \"if results_dict:\\n\",\n",
        "        \"    sns.set_style('whitegrid')\\n\",\n",
        "        \"    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # Accuracy comparison\\n\",\n",
        "        \"    scenarios = list(results_dict.keys())\\n\",\n",
        "        \"    accuracies = [results_dict[s]['accuracy'] for s in scenarios]\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    colors = ['green', 'orange', 'blue', 'red']\\n\",\n",
        "        \"    bars = axes[0].bar(scenarios, accuracies, color=colors[:len(scenarios)], \\n\",\n",
        "        \"                        alpha=0.7, edgecolor='black', linewidth=2)\\n\",\n",
        "        \"    axes[0].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\\n\",\n",
        "        \"    axes[0].set_title(f'{DATASET.upper()} - Accuracy Comparison', fontsize=13, fontweight='bold')\\n\",\n",
        "        \"    axes[0].set_ylim([0.5, 1.0])\\n\",\n",
        "        \"    axes[0].grid(axis='y', alpha=0.3)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    for bar, acc in zip(bars, accuracies):\\n\",\n",
        "        \"        height = bar.get_height()\\n\",\n",
        "        \"        axes[0].text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
        "        \"                    f'{acc:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # F1-Score comparison\\n\",\n",
        "        \"    f1_scores = [results_dict[s]['f1_score'] for s in scenarios]\\n\",\n",
        "        \"    bars2 = axes[1].bar(scenarios, f1_scores, color=colors[:len(scenarios)], \\n\",\n",
        "        \"                         alpha=0.7, edgecolor='black', linewidth=2)\\n\",\n",
        "        \"    axes[1].set_ylabel('F1-Score', fontsize=12, fontweight='bold')\\n\",\n",
        "        \"    axes[1].set_title(f'{DATASET.upper()} - F1-Score Comparison', fontsize=13, fontweight='bold')\\n\",\n",
        "        \"    axes[1].set_ylim([0.5, 1.0])\\n\",\n",
        "        \"    axes[1].grid(axis='y', alpha=0.3)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    for bar, f1 in zip(bars2, f1_scores):\\n\",\n",
        "        \"        height = bar.get_height()\\n\",\n",
        "        \"        axes[1].text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
        "        \"                    f'{f1:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    plt.tight_layout()\\n\",\n",
        "        \"    plt.savefig('results_comparison.png', dpi=150, bbox_inches='tight')\\n\",\n",
        "        \"    plt.show()\\n\",\n",
        "        \"    print('‚úÖ Visualization saved as results_comparison.png')\\nelse:\\n\",\n",
        "        \"    print('‚ö†Ô∏è  No results to visualize')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 13. Download Results\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"export\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"from google.colab import files\\n\",\n",
        "        \"import shutil\\n\",\n",
        "        \"\\n\",\n",
        "        \"print('\\\\n' + '='*70)\\n\",\n",
        "        \"print('üì• EXPORTING RESULTS')\\n\",\n",
        "        \"print('='*70)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create zip with results\\n\",\n",
        "        \"if RESULTS_BASE.exists():\\n\",\n",
        "        \"    print('\\\\nCreating results archive...')\\n\",\n",
        "        \"    shutil.make_archive('mhealth_results', 'zip', RESULTS_BASE)\\n\",\n",
        "        \"    print('‚úÖ Archive created: mhealth_results.zip')\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    # Download\\n\",\n",
        "        \"    files.download('mhealth_results.zip')\\n\",\n",
        "        \"    print('‚úÖ Downloaded to your computer!')\\nelse:\\n\",\n",
        "        \"    print('‚ö†Ô∏è  No results directory found')\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Also download visualization if exists\\n\",\n",
        "        \"if os.path.exists('results_comparison.png'):\\n\",\n",
        "        \"    files.download('results_comparison.png')\\n\",\n",
        "        \"    print('‚úÖ Downloaded visualization!')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 14. Summary\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"tags\": [\"summary\"]\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"print('\\\\n' + '='*70)\\n\",\n",
        "        \"print('‚úÖ PIPELINE COMPLETE')\\n\",\n",
        "        \"print('='*70)\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f'\\\\nüìä Execution Summary:')\\n\",\n",
        "        \"print(f'   Dataset: {DATASET}')\\n\",\n",
        "        \"print(f'   Scenarios run: {[s for s, v in RUN_SCENARIOS.items() if v]}')\\n\",\n",
        "        \"print(f'   Epochs: {TRAIN_PARAMS[\\\"epochs\\\"]}')\\n\",\n",
        "        \"print(f'   Results scenarios: {list(results_dict.keys()) if results_dict else \\\"None\\\"}')\\n\",\n",
        "        \"\\n\",\n",
        "        \"if results_dict:\\n\",\n",
        "        \"    baseline_acc = results_dict.get('baseline', {}).get('accuracy', 0)\\n\",\n",
        "        \"    dp_acc = results_dict.get('dp', {}).get('accuracy', 0)\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    if baseline_acc > 0 and dp_acc > 0:\\n\",\n",
        "        \"        drop = (baseline_acc - dp_acc) * 100\\n\",\n",
        "        \"        print(f'\\\\nüìà Privacy-Utility Tradeoff:')\\n\",\n",
        "        \"        print(f'   Baseline Accuracy: {baseline_acc:.4f}')\\n\",\n",
        "        \"        print(f'   DP Accuracy (Œµ=1.0): {dp_acc:.4f}')\\n\",\n",
        "        \"        print(f'   Accuracy Drop: {drop:.2f}%')\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f'\\\\nüìÅ Results Location:')\\n\",\n",
        "        \"print(f'   Local: {RESULTS_BASE}')\\n\",\n",
        "        \"print(f'   Drive: {DRIVE_BASE}/mhealth-privacy/results')\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f'\\\\nüöÄ Next Steps:')\\n\",\n",
        "        \"print(f'   1. Analyze results in results_comparison.png')\\n\",\n",
        "        \"print(f'   2. Run with different epsilon values: [0.5, 1.0, 2.0, 5.0]')\\n\",\n",
        "        \"print(f'   3. Vary n_clients for FL experiments')\\n\",\n",
        "        \"print(f'   4. Generate paper plots and tables')\\n\",\n",
        "        \"\\n\",\n",
        "        \"print('\\\\n' + '='*70)\"\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  \"metadata\": {\n",
        "    \"kernelspec\": {\n",
        "      \"display_name\": \"Python 3\",\n",
        "      \"language\": \"python\",\n",
        "      \"name\": \"python3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\",\n",
        "      \"version\": \"3.10.12\"\n",
        "    }\n",
        "  },\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 5\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 15: Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print('üì• Preparing downloads...')\n",
        "\n",
        "# Download individual files\n",
        "files.download('results.json')\n",
        "files.download('results_comparison.png')\n",
        "files.download('privacy_utility_tradeoff.png')\n",
        "\n",
        "print('‚úÖ All files downloaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cell 16: Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\n' + '='*70)\n",
        "print('PIPELINE SUMMARY')\n",
        "print('='*70)\n",
        "\n",
        "print(f'\\n‚úÖ DATASETS LOADED:')\n",
        "print(f'   Sleep-EDF: {X_train_sleep.shape[0]} train, {X_val_sleep.shape[0]} val, {X_test_sleep.shape[0]} test')\n",
        "print(f'   WESAD: {X_train_wesad.shape[0]} train, {X_val_wesad.shape[0]} val, {X_test_wesad.shape[0]} test')\n",
        "\n",
        "print(f'\\n‚úÖ MODELS TRAINED:')\n",
        "print(f'   Sleep-EDF Baseline: {results_baseline_sleep[\"accuracy\"]:.4f}')\n",
        "print(f'   Sleep-EDF DP (Œµ=1.0): {results_dp_sleep[\"accuracy\"]:.4f}')\n",
        "print(f'   WESAD Baseline: {results_baseline_wesad[\"accuracy\"]:.4f}')\n",
        "\n",
        "print(f'\\nüìä PRIVACY-UTILITY ANALYSIS:')\n",
        "acc_drop = (results_baseline_sleep['accuracy'] - results_dp_sleep['accuracy']) * 100\n",
        "print(f'   Accuracy drop (Œµ=1.0): {acc_drop:.2f}%')\n",
        "print(f'   Privacy guarantee (Œµ): {results_dp_sleep[\"final_epsilon\"]:.4f}')\n",
        "\n",
        "print(f'\\nüìÅ FILES GENERATED:')\n",
        "print(f'   ‚úì results.json')\n",
        "print(f'   ‚úì results_comparison.png')\n",
        "print(f'   ‚úì privacy_utility_tradeoff.png')\n",
        "\n",
        "print(f'\\nüéâ Pipeline completed successfully!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
