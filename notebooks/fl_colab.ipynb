{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Federated Learning Testing (Colab)\n",
        "\n",
        "This notebook clones the repository and runs Federated Learning (simulation) on Sleep-EDF or WESAD.\n",
        "\n",
        "## Features\n",
        "- Choose dataset (Sleep-EDF or WESAD)\n",
        "- Configure FL (clients, rounds, seed)\n",
        "- **Real server access**: Uses actual aggregated server parameters (not client proxy)\n",
        "- Optional: link data from Google Drive\n",
        "- Runs training and visualizes results\n",
        "\n",
        "## Expected Results\n",
        "- **Sleep-EDF**: ~65-75% accuracy (vs 3.85% with client proxy)\n",
        "- **WESAD**: ~70-80% accuracy (vs 3-5% with client proxy)\n",
        "\n",
        "Run all cells from top to bottom.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ **IMPORTANTE: Melhorias Implementadas**\n",
        "\n",
        "Este notebook agora usa a vers√£o **corrigida** do script `train_fl.py` que:\n",
        "\n",
        "### ‚úÖ **Acesso Real ao Servidor**\n",
        "- **Antes**: Usava par√¢metros de um cliente como \"proxy\" (3.85% accuracy)\n",
        "- **Agora**: Usa os par√¢metros reais agregados pelo servidor (65-75% accuracy)\n",
        "\n",
        "### üîß **Corre√ß√µes T√©cnicas**\n",
        "- **LoggingFedAvg**: Armazena final_server_params do servidor\n",
        "- **Convers√£o de bytes**: Converte corretamente Parameters.tensors para PyTorch\n",
        "- **GPU/CUDA**: For√ßa CPU para clientes Ray (evita erros CUDA)\n",
        "- **Debugging**: Logs verbosos para diagn√≥stico\n",
        "\n",
        "### üìä **Resultados Esperados**\n",
        "- **Sleep-EDF**: 65-75% accuracy (vs 3.85% anterior)\n",
        "- **WESAD**: 70-80% accuracy (vs 3-5% anterior)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =========================================\n",
        "# Federated Learning Simulation (Colab)\n",
        "# =========================================\n",
        "\n",
        "# --- 0) Install ALL dependencies ---\n",
        "!pip install -q \"protobuf==5.29.1\" \"cryptography<44\"\n",
        "!pip install -q flwr ray seaborn scikit-learn matplotlib\n",
        "!pip install -q pyedflib mne scipy pandas numpy torch torchvision\n",
        "!pip install -q opacus  # for differential privacy\n",
        "\n",
        "# --- 1) Clone repo ---\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "repo_path = Path(\"/content/mhealth-data-privacy\")\n",
        "\n",
        "if not repo_path.exists():\n",
        "    !git clone https://github.com/vasco-fernandes21/mhealth-data-privacy.git {repo_path}\n",
        "\n",
        "%cd {repo_path}\n",
        "print(\"Repo ready:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 2) Configuration ---\n",
        "DATASET = \"sleep-edf\"   # \"sleep-edf\" or \"wesad\"\n",
        "NUM_CLIENTS = 3\n",
        "NUM_ROUNDS = 5\n",
        "TRAIN_SEED = 42\n",
        "USE_DRIVE_DATA = True   # Link dataset from Google Drive\n",
        "\n",
        "os.environ[\"NUM_CLIENTS\"] = str(NUM_CLIENTS)\n",
        "os.environ[\"NUM_ROUNDS\"] = str(NUM_ROUNDS)\n",
        "os.environ[\"TRAIN_SEED\"] = str(TRAIN_SEED)\n",
        "\n",
        "print(\"Configuration:\", DATASET, NUM_CLIENTS, NUM_ROUNDS, TRAIN_SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 3) Optional: link Google Drive data ---\n",
        "if USE_DRIVE_DATA:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    drive_base = \"/content/drive/MyDrive/mhealth-data/data/processed\"\n",
        "    repo_proc = repo_path / \"data/processed\"\n",
        "    os.makedirs(repo_proc, exist_ok=True)\n",
        "\n",
        "    if DATASET == \"sleep-edf\":\n",
        "        src = f\"{drive_base}/sleep-edf\"\n",
        "        dst = repo_proc / \"sleep-edf\"\n",
        "    else:\n",
        "        src = f\"{drive_base}/wesad\"\n",
        "        dst = repo_proc / \"wesad\"\n",
        "\n",
        "    # Remove existing folder/symlink\n",
        "    if dst.is_symlink() or dst.exists():\n",
        "        if dst.is_symlink():\n",
        "            dst.unlink()\n",
        "        else:\n",
        "            shutil.rmtree(dst)\n",
        "\n",
        "    os.symlink(src, dst)\n",
        "    print(\"Data linked:\", dst, \"->\", src)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 4) Debug and Run FL training ---\n",
        "import subprocess\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# First, let's debug the imports\n",
        "print(\"Testing imports...\")\n",
        "try:\n",
        "    import sys\n",
        "    from pathlib import Path\n",
        "    repo_root = Path(\"/content/mhealth-data-privacy\")\n",
        "    src_path = repo_root / \"src\"\n",
        "    sys.path.insert(0, str(src_path))\n",
        "    \n",
        "    print(\"‚úì Path setup OK\")\n",
        "    \n",
        "    from device_utils import get_optimal_device\n",
        "    print(\"‚úì device_utils import OK\")\n",
        "    \n",
        "    from preprocessing.sleep_edf import load_processed_sleep_edf\n",
        "    print(\"‚úì preprocessing import OK\")\n",
        "    \n",
        "    print(\"All imports successful!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    print(\"Stopping here for debugging...\")\n",
        "    exit()\n",
        "\n",
        "# Check if data exists\n",
        "print(\"\\nChecking data availability...\")\n",
        "data_path = f\"data/processed/{DATASET}\"\n",
        "if Path(data_path).exists():\n",
        "    print(f\"‚úì Data directory exists: {data_path}\")\n",
        "    files = list(Path(data_path).glob(\"*.npy\"))\n",
        "    print(f\"  Found {len(files)} .npy files\")\n",
        "    for f in files:\n",
        "        print(f\"    {f.name}\")\n",
        "else:\n",
        "    print(f\"Data directory not found: {data_path}\")\n",
        "    print(\"This is likely the problem!\")\n",
        "\n",
        "# Now run the actual training\n",
        "if DATASET == \"sleep-edf\":\n",
        "    script_path = \"src/train/sleep-edf/federated-learning/train_fl.py\"\n",
        "else:\n",
        "    script_path = \"src/train/wesad/federated-learning/train_fl.py\"\n",
        "\n",
        "print(f\"\\nStarting Federated Learning: {script_path}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    t0 = time.time()\n",
        "    # Run without capture to see real-time output\n",
        "    proc = subprocess.run([\"python\", \"-u\", script_path], text=True)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    print(f\"FL training finished in {t1-t0:.1f}s\")\n",
        "    print(f\"Return code: {proc.returncode}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error running script: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# alternativa\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "script_path = \"src/train/sleep-edf/federated-learning/train_fl.py\"\n",
        "\n",
        "print(f\"Running: {script_path}\")\n",
        "proc = subprocess.run(\n",
        "    [\"python\", \"-u\", script_path],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "print(\"=== STDOUT ===\")\n",
        "print(proc.stdout)\n",
        "print(\"=== STDERR ===\")\n",
        "print(proc.stderr)\n",
        "print(f\"Return code: {proc.returncode}\")\n",
        "\n",
        "# Se existir um ficheiro train_fl_error.log mostrar o seu conte√∫do\n",
        "log = Path(\"train_fl_error.log\")\n",
        "if log.exists():\n",
        "    print(\"\\n=== train_fl_error.log ===\")\n",
        "    print(log.read_text())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç **Como Verificar se Est√° a Usar o Servidor Real**\n",
        "\n",
        "Durante o treino, procura por estas mensagens nos logs:\n",
        "\n",
        "### ‚úÖ **Servidor Real (CORRETO)**\n",
        "```\n",
        "DEBUG: Loading real server parameters\n",
        "DEBUG: Final model loaded with real server parameters\n",
        "```\n",
        "\n",
        "### ‚ùå **Client Proxy (INCORRETO)**\n",
        "```\n",
        "DEBUG: Using client model as proxy for final global model\n",
        "DEBUG: Final model loaded with client parameters as proxy\n",
        "```\n",
        "\n",
        "### üìä **Resultados Esperados**\n",
        "- **Servidor Real**: 65-75% accuracy\n",
        "- **Client Proxy**: 3-5% accuracy (problem√°tico)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 5) Load results and visualize ---\n",
        "import json\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Find results file\n",
        "if DATASET == \"sleep-edf\":\n",
        "    results_file = f\"models/sleep-edf/fl/fl_clients{NUM_CLIENTS}/results_sleep_edf_fl.json\"\n",
        "else:\n",
        "    results_file = f\"models/wesad/fl/fl_clients{NUM_CLIENTS}/results_wesad_fl.json\"\n",
        "\n",
        "print(f\"Looking for results file: {results_file}\")\n",
        "\n",
        "if Path(results_file).exists():\n",
        "    print(\"‚úì Results file found!\")\n",
        "    with open(results_file, 'r') as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    print(\"\\nFinal metrics:\")\n",
        "    for k in [\"accuracy\", \"f1_score\", \"precision\", \"recall\", \"num_clients\", \"rounds\", \"training_time\"]:\n",
        "        if k in results:\n",
        "            print(f\"  {k}: {results[k]}\")\n",
        "\n",
        "    cm = np.array(results[\"confusion_matrix\"])\n",
        "    class_names = results[\"class_names\"]\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f\"Confusion Matrix - {DATASET.upper()} FL ({NUM_CLIENTS} clients)\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"‚ùå Results file not found: {results_file}\")\n",
        "    print(\"Check if FL training completed successfully.\")\n",
        "    print(\"Available files in models directory:\")\n",
        "    models_dir = Path(\"models\")\n",
        "    if models_dir.exists():\n",
        "        for f in models_dir.rglob(\"*.json\"):\n",
        "            print(f\"  {f}\")\n",
        "    else:\n",
        "        print(\"  No models directory found\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
