{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Analysis and Results\n",
        "\n",
        "Este notebook realiza a an√°lise final comparando todas as abordagens: Baseline, Differential Privacy e Federated Learning.\n",
        "\n",
        "## O que este notebook faz:\n",
        "1. Carrega todos os resultados (baseline, DP, FL)\n",
        "2. Cria visualiza√ß√µes comparativas\n",
        "3. Analisa trade-offs entre privacidade e performance\n",
        "4. Gera tabelas de resultados\n",
        "5. Cria dashboard final\n",
        "6. Salva relat√≥rio completo\n",
        "\n",
        "**Pr√©-requisitos**: Execute todos os notebooks anteriores (00-05).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 1: Load All Results\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COMPREHENSIVE ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import modules\n",
        "from src.evaluation.metrics import load_evaluation_results, compare_models, create_results_summary\n",
        "from src.evaluation.visualization import (\n",
        "    plot_tradeoff_curve, plot_comparison_bars, plot_privacy_analysis,\n",
        "    create_summary_dashboard\n",
        ")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "RESULTS_PATH = '/content/drive/MyDrive/mhealth-data/results'\n",
        "\n",
        "print(\"Loading all results...\")\n",
        "\n",
        "# Load baseline results\n",
        "baseline_results = {}\n",
        "if os.path.exists(f'{RESULTS_PATH}/baseline_results.json'):\n",
        "    baseline_results = load_evaluation_results(f'{RESULTS_PATH}/baseline_results.json')\n",
        "    print(f\"‚úÖ Baseline results loaded: {len(baseline_results)} models\")\n",
        "\n",
        "# Load DP results\n",
        "dp_results = {}\n",
        "if os.path.exists(f'{RESULTS_PATH}/dp_results.json'):\n",
        "    dp_results = load_evaluation_results(f'{RESULTS_PATH}/dp_results.json')\n",
        "    print(f\"‚úÖ DP results loaded: {len(dp_results)} models\")\n",
        "\n",
        "# Load FL results\n",
        "fl_results = {}\n",
        "if os.path.exists(f'{RESULTS_PATH}/fl_results.json'):\n",
        "    fl_results = load_evaluation_results(f'{RESULTS_PATH}/fl_results.json')\n",
        "    print(f\"‚úÖ FL results loaded: {len(fl_results)} models\")\n",
        "\n",
        "# Combine all results\n",
        "all_results = {}\n",
        "all_results.update(baseline_results)\n",
        "all_results.update(dp_results)\n",
        "all_results.update(fl_results)\n",
        "\n",
        "print(f\"\\nTotal models analyzed: {len(all_results)}\")\n",
        "print(f\"Techniques: {set([results.get('privacy_technique', 'Unknown') for results in all_results.values()])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 2: Create Results Summary Table\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if all_results:\n",
        "    # Create comprehensive summary\n",
        "    summary_df = create_results_summary(all_results, f'{RESULTS_PATH}/comprehensive_results_summary.csv')\n",
        "    \n",
        "    print(\"Results Summary Table:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "    \n",
        "    # Save detailed summary\n",
        "    summary_df.to_csv(f'{RESULTS_PATH}/detailed_results_summary.csv', index=False)\n",
        "    print(f\"\\n‚úÖ Detailed summary saved to: {RESULTS_PATH}/detailed_results_summary.csv\")\n",
        "    \n",
        "    # Create comparison by technique\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"COMPARISON BY TECHNIQUE\")\n",
        "    print(\"-\"*50)\n",
        "    \n",
        "    technique_comparison = summary_df.groupby('Privacy_Technique').agg({\n",
        "        'Accuracy': ['mean', 'std'],\n",
        "        'F1-Score': ['mean', 'std'],\n",
        "        'Model': 'count'\n",
        "    }).round(4)\n",
        "    \n",
        "    print(technique_comparison)\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No results found. Please run training notebooks first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 3: Create Comprehensive Visualizations\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING COMPREHENSIVE VISUALIZATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if all_results:\n",
        "    # 1. Privacy vs. Performance Trade-off Analysis\n",
        "    print(\"Creating privacy analysis...\")\n",
        "    plot_privacy_analysis(\n",
        "        all_results,\n",
        "        save_path=f'{RESULTS_PATH}/privacy_analysis_comprehensive.png',\n",
        "        title='Comprehensive Privacy Analysis'\n",
        "    )\n",
        "    \n",
        "    # 2. Model Comparison Bars\n",
        "    print(\"Creating model comparison...\")\n",
        "    plot_comparison_bars(\n",
        "        all_results,\n",
        "        metrics=['accuracy', 'f1_score'],\n",
        "        save_path=f'{RESULTS_PATH}/model_comparison_comprehensive.png',\n",
        "        title='Comprehensive Model Comparison'\n",
        "    )\n",
        "    \n",
        "    # 3. Trade-off Curves for DP\n",
        "    dp_models = {k: v for k, v in all_results.items() if v.get('privacy_technique') == 'DP'}\n",
        "    if dp_models:\n",
        "        print(\"Creating DP trade-off curves...\")\n",
        "        plot_tradeoff_curve(\n",
        "            dp_models,\n",
        "            metric='accuracy',\n",
        "            privacy_param='epsilon',\n",
        "            save_path=f'{RESULTS_PATH}/dp_tradeoff_comprehensive.png',\n",
        "            title='Differential Privacy: Privacy vs. Performance Trade-off'\n",
        "        )\n",
        "    \n",
        "    # 4. Summary Dashboard\n",
        "    print(\"Creating summary dashboard...\")\n",
        "    create_summary_dashboard(\n",
        "        all_results,\n",
        "        save_path=f'{RESULTS_PATH}/summary_dashboard.png'\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ All visualizations created successfully!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No results to visualize\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 4: Statistical Analysis\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STATISTICAL ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if all_results:\n",
        "    # Extract baseline results for comparison\n",
        "    baseline_models = {k: v for k, v in all_results.items() if v.get('privacy_technique') == 'None'}\n",
        "    dp_models = {k: v for k, v in all_results.items() if v.get('privacy_technique') == 'DP'}\n",
        "    fl_models = {k: v for k, v in all_results.items() if v.get('privacy_technique') == 'FL'}\n",
        "    \n",
        "    print(\"Statistical Analysis Results:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Analyze each dataset\n",
        "    for dataset in ['sleep_edf', 'wesad']:\n",
        "        print(f\"\\n{dataset.upper()} Dataset Analysis:\")\n",
        "        \n",
        "        # Find baseline for this dataset\n",
        "        dataset_baseline = None\n",
        "        for model_name, results in baseline_models.items():\n",
        "            if results.get('dataset') == dataset:\n",
        "                dataset_baseline = results\n",
        "                break\n",
        "        \n",
        "        if dataset_baseline:\n",
        "            baseline_acc = dataset_baseline['metrics']['accuracy']\n",
        "            baseline_f1 = dataset_baseline['metrics']['f1_score']\n",
        "            \n",
        "            print(f\"  Baseline: Accuracy={baseline_acc:.4f}, F1={baseline_f1:.4f}\")\n",
        "            \n",
        "            # Compare DP models\n",
        "            dataset_dp = {k: v for k, v in dp_models.items() if v.get('dataset') == dataset}\n",
        "            if dataset_dp:\n",
        "                print(f\"  DP Models:\")\n",
        "                for model_name, results in dataset_dp.items():\n",
        "                    acc = results['metrics']['accuracy']\n",
        "                    f1 = results['metrics']['f1_score']\n",
        "                    epsilon = results.get('epsilon', 'N/A')\n",
        "                    acc_degradation = baseline_acc - acc\n",
        "                    f1_degradation = baseline_f1 - f1\n",
        "                    print(f\"    {model_name}: Acc={acc:.4f} (-{acc_degradation:.4f}), F1={f1:.4f} (-{f1_degradation:.4f}), Œµ={epsilon}\")\n",
        "            \n",
        "            # Compare FL models\n",
        "            dataset_fl = {k: v for k, v in fl_models.items() if v.get('dataset') == dataset}\n",
        "            if dataset_fl:\n",
        "                print(f\"  FL Models:\")\n",
        "                for model_name, results in dataset_fl.items():\n",
        "                    acc = results['metrics']['accuracy']\n",
        "                    f1 = results['metrics']['f1_score']\n",
        "                    n_clients = results.get('n_clients', 'N/A')\n",
        "                    acc_degradation = baseline_acc - acc\n",
        "                    f1_degradation = baseline_f1 - f1\n",
        "                    print(f\"    {model_name}: Acc={acc:.4f} (-{acc_degradation:.4f}), F1={f1:.4f} (-{f1_degradation:.4f}), Clients={n_clients}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Statistical analysis completed!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No results for statistical analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 5: Generate Final Report\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING FINAL REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create final report\n",
        "report = {\n",
        "    'project': 'Privacy-Preserving Health Data Analysis',\n",
        "    'datasets': ['Sleep-EDF', 'WESAD'],\n",
        "    'techniques': ['Baseline', 'Differential Privacy', 'Federated Learning'],\n",
        "    'total_models': len(all_results),\n",
        "    'summary': summary_df.to_dict('records') if 'summary_df' in locals() else [],\n",
        "    'key_findings': []\n",
        "}\n",
        "\n",
        "# Add key findings\n",
        "if all_results:\n",
        "    # Find best performing models\n",
        "    best_accuracy = max(all_results.items(), key=lambda x: x[1]['metrics']['accuracy'])\n",
        "    best_f1 = max(all_results.items(), key=lambda x: x[1]['metrics']['f1_score'])\n",
        "    \n",
        "    report['key_findings'].extend([\n",
        "        f\"Best Accuracy: {best_accuracy[0]} ({best_accuracy[1]['metrics']['accuracy']:.4f})\",\n",
        "        f\"Best F1-Score: {best_f1[0]} ({best_f1[1]['metrics']['f1_score']:.4f})\"\n",
        "    ])\n",
        "    \n",
        "    # Analyze privacy trade-offs\n",
        "    if dp_models:\n",
        "        dp_accuracies = [results['metrics']['accuracy'] for results in dp_models.values()]\n",
        "        avg_dp_accuracy = np.mean(dp_accuracies)\n",
        "        report['key_findings'].append(f\"Average DP Accuracy: {avg_dp_accuracy:.4f}\")\n",
        "    \n",
        "    if fl_models:\n",
        "        fl_accuracies = [results['metrics']['accuracy'] for results in fl_models.values()]\n",
        "        avg_fl_accuracy = np.mean(fl_accuracies)\n",
        "        report['key_findings'].append(f\"Average FL Accuracy: {avg_fl_accuracy:.4f}\")\n",
        "\n",
        "# Save final report\n",
        "import json\n",
        "with open(f'{RESULTS_PATH}/final_report.json', 'w') as f:\n",
        "    json.dump(report, f, indent=2)\n",
        "\n",
        "print(\"Final Report Generated:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Project: {report['project']}\")\n",
        "print(f\"Datasets: {', '.join(report['datasets'])}\")\n",
        "print(f\"Techniques: {', '.join(report['techniques'])}\")\n",
        "print(f\"Total Models: {report['total_models']}\")\n",
        "print(\"\\nKey Findings:\")\n",
        "for finding in report['key_findings']:\n",
        "    print(f\"  ‚Ä¢ {finding}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Final report saved to: {RESULTS_PATH}/final_report.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 6: Project Completion Summary\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROJECT COMPLETION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"üéâ Privacy-Preserving Health Data Analysis Project Complete!\")\n",
        "print(\"\\nWhat was accomplished:\")\n",
        "print(\"‚úÖ Preprocessed Sleep-EDF and WESAD datasets\")\n",
        "print(\"‚úÖ Trained baseline LSTM models\")\n",
        "print(\"‚úÖ Implemented Differential Privacy with multiple epsilon values\")\n",
        "print(\"‚úÖ Implemented Federated Learning with multiple client configurations\")\n",
        "print(\"‚úÖ Comprehensive evaluation and comparison\")\n",
        "print(\"‚úÖ Statistical analysis of privacy-performance trade-offs\")\n",
        "print(\"‚úÖ Generated visualizations and final report\")\n",
        "\n",
        "print(f\"\\nResults saved in: {RESULTS_PATH}\")\n",
        "print(\"Files generated:\")\n",
        "print(\"  ‚Ä¢ comprehensive_results_summary.csv\")\n",
        "print(\"  ‚Ä¢ detailed_results_summary.csv\")\n",
        "print(\"  ‚Ä¢ privacy_analysis_comprehensive.png\")\n",
        "print(\"  ‚Ä¢ model_comparison_comprehensive.png\")\n",
        "print(\"  ‚Ä¢ dp_tradeoff_comprehensive.png\")\n",
        "print(\"  ‚Ä¢ summary_dashboard.png\")\n",
        "print(\"  ‚Ä¢ final_report.json\")\n",
        "\n",
        "print(\"\\nNext steps for your thesis:\")\n",
        "print(\"1. Review the results and visualizations\")\n",
        "print(\"2. Write the methodology section using the implemented code\")\n",
        "print(\"3. Analyze the trade-offs between privacy and performance\")\n",
        "print(\"4. Discuss implications for mobile health applications\")\n",
        "print(\"5. Create conclusions and recommendations\")\n",
        "\n",
        "print(\"\\nüöÄ Your project is ready for thesis writing!\")\n",
        "print(\"All code is modular and well-documented for reproducibility.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
