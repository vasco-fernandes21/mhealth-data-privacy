{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WESAD PyTorch Training - Google Colab\n",
        "\n",
        "This notebook trains PyTorch models for stress detection using the WESAD (Wearable Stress and Affect Detection) dataset.\n",
        "\n",
        "## Features:\n",
        "- Baseline LSTM model for binary stress classification\n",
        "- Differential Privacy (DP-SGD) training option\n",
        "- Efficient data loading for physiological signals\n",
        "- Clean logs during training (no emojis)\n",
        "- Early stopping and learning rate scheduling\n",
        "- Memory and speed optimizations\n",
        "- Automatic hardware acceleration (CUDA > MPS > CPU)\n",
        "\n",
        "## Requirements:\n",
        "- Google Colab with GPU enabled\n",
        "- Data in Google Drive: `mydrive/mhealth-data/data/processed/wesad/`\n",
        "\n",
        "## Training Options:\n",
        "1. **Baseline**: Standard LSTM model (~80% accuracy)\n",
        "2. **Differential Privacy**: DP-SGD with privacy guarantees\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Initial Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install necessary dependencies\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install numpy pandas scikit-learn matplotlib seaborn\n",
        "!pip install mne pyedflib opacus\n",
        "\n",
        "# Clone the repository\n",
        "!git clone https://github.com/vasco-fernandes21/mhealth-data-privacy.git\n",
        "import sys\n",
        "sys.path.append('/content/mhealth-data-privacy')\n",
        "\n",
        "print(\"Dependencies installed and repository cloned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if data exists\n",
        "import os\n",
        "data_path = '/content/drive/MyDrive/mhealth-data/data/processed/wesad'\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    print(f\"Data found at: {data_path}\")\n",
        "\n",
        "    # List files\n",
        "    files = os.listdir(data_path)\n",
        "    print(f\"Available files: {files}\")\n",
        "\n",
        "    # Check file sizes\n",
        "    for file in ['X_train.npy', 'y_train.npy', 'X_val.npy', 'y_val.npy', 'X_test.npy', 'y_test.npy']:\n",
        "        if file in files:\n",
        "            size = os.path.getsize(os.path.join(data_path, file))\n",
        "            print(f\"  {file}: {size / (1024*1024):.1f} MB\")\n",
        "        else:\n",
        "            print(f\"  {file} not found\")\n",
        "else:\n",
        "    print(f\"Data not found at: {data_path}\")\n",
        "    print(\"Make sure the data is in the correct path on Google Drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training\n",
        "\n",
        "Choose your training option:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option A: Baseline LSTM Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run baseline training using the repository script\n",
        "import os, shutil\n",
        "\n",
        "repo_data_dir = '/content/mhealth-data-privacy/data/processed/wesad'\n",
        "drive_data_dir = '/content/drive/MyDrive/mhealth-data/data/processed/wesad'\n",
        "models_dir = '/content/mhealth-data-privacy/models/wesad/baseline'\n",
        "results_dir = '/content/mhealth-data-privacy/results/wesad/baseline'\n",
        "\n",
        "# Ensure output directories\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Create symbolic link from Drive data to expected path\n",
        "os.makedirs('/content/mhealth-data-privacy/data/processed', exist_ok=True)\n",
        "if os.path.islink(repo_data_dir) or os.path.exists(repo_data_dir):\n",
        "    try:\n",
        "        if os.path.islink(repo_data_dir):\n",
        "            os.unlink(repo_data_dir)\n",
        "        else:\n",
        "            shutil.rmtree(repo_data_dir)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning when removing old destination: {e}\")\n",
        "\n",
        "# Create symlink\n",
        "!ln -sf \"$drive_data_dir\" \"$repo_data_dir\"\n",
        "print(f\"Data referenced via symlink: {repo_data_dir} -> {drive_data_dir}\")\n",
        "\n",
        "print(f\"Starting baseline LSTM training with data from: {drive_data_dir}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Run the baseline training script\n",
        "!python /content/mhealth-data-privacy/src/train/wesad/train_baseline.py\n",
        "\n",
        "print(\"Baseline training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option B: Differential Privacy Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run differential privacy training\n",
        "import os, shutil\n",
        "\n",
        "repo_data_dir = '/content/mhealth-data-privacy/data/processed/wesad'\n",
        "drive_data_dir = '/content/drive/MyDrive/mhealth-data/data/processed/wesad'\n",
        "models_dir = '/content/mhealth-data-privacy/models/wesad/dp'\n",
        "results_dir = '/content/mhealth-data-privacy/results/wesad/dp'\n",
        "\n",
        "# Ensure output directories\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Create symbolic link from Drive data to expected path\n",
        "os.makedirs('/content/mhealth-data-privacy/data/processed', exist_ok=True)\n",
        "if os.path.islink(repo_data_dir) or os.path.exists(repo_data_dir):\n",
        "    try:\n",
        "        if os.path.islink(repo_data_dir):\n",
        "            os.unlink(repo_data_dir)\n",
        "        else:\n",
        "            shutil.rmtree(repo_data_dir)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning when removing old destination: {e}\")\n",
        "\n",
        "# Create symlink\n",
        "!ln -sf \"$drive_data_dir\" \"$repo_data_dir\"\n",
        "print(f\"Data referenced via symlink: {repo_data_dir} -> {drive_data_dir}\")\n",
        "\n",
        "print(f\"Starting differential privacy training with data from: {drive_data_dir}\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Using DPLSTM for Opacus compatibility\")\n",
        "\n",
        "# Run the differential privacy training script\n",
        "!python /content/mhealth-data-privacy/src/train/wesad/differential_privacy/train_dp.py\n",
        "\n",
        "print(\"Differential privacy training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and analyze results\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Check which results are available\n",
        "baseline_results_path = '/content/mhealth-data-privacy/models/wesad/baseline/results_wesad_baseline.json'\n",
        "dp_results_path = '/content/mhealth-data-privacy/models/wesad/dp/results_wesad_dp.json'\n",
        "\n",
        "results_to_show = []\n",
        "\n",
        "if os.path.exists(baseline_results_path):\n",
        "    with open(baseline_results_path, 'r') as f:\n",
        "        baseline_results = json.load(f)\n",
        "    results_to_show.append(('Baseline LSTM', baseline_results))\n",
        "\n",
        "if os.path.exists(dp_results_path):\n",
        "    with open(dp_results_path, 'r') as f:\n",
        "        dp_results = json.load(f)\n",
        "    results_to_show.append(('Differential Privacy', dp_results))\n",
        "\n",
        "if results_to_show:\n",
        "    print(\"FINAL RESULTS:\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for model_name, results in results_to_show:\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(f\"   Accuracy:  {results['accuracy']:.4f}\")\n",
        "        print(f\"   Precision: {results['precision']:.4f}\")\n",
        "        print(f\"   Recall:    {results['recall']:.4f}\")\n",
        "        print(f\"   F1-Score:  {results['f1_score']:.4f}\")\n",
        "        \n",
        "        if 'epsilon' in results:\n",
        "            print(f\"   Privacy (Îµ): {results['epsilon']:.4f}\")\n",
        "        \n",
        "        if 'training_time' in results:\n",
        "            print(f\"   Training Time: {results['training_time']:.1f}s\")\n",
        "\n",
        "    # Plot confusion matrices\n",
        "    fig, axes = plt.subplots(1, len(results_to_show), figsize=(6*len(results_to_show), 5))\n",
        "    if len(results_to_show) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, (model_name, results) in enumerate(results_to_show):\n",
        "        cm = np.array(results['confusion_matrix'])\n",
        "        class_names = results['class_names']\n",
        "        \n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=class_names, yticklabels=class_names, ax=axes[i])\n",
        "        axes[i].set_title(f'Confusion Matrix - {model_name}')\n",
        "        axes[i].set_xlabel('Predicted')\n",
        "        axes[i].set_ylabel('Actual')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"No results found\")\n",
        "    print(\"Run the training cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Results Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips and Troubleshooting\n",
        "\n",
        "### Common Issues:\n",
        "\n",
        "1. **Data not found:**\n",
        "   - Check if path `mydrive/mhealth-data/data/processed/wesad/` is correct\n",
        "   - Ensure all `.npy` files are present\n",
        "\n",
        "2. **GPU not available:**\n",
        "   - Go to Runtime â Change runtime type â Hardware accelerator â GPU\n",
        "   - Model will work on CPU but will be slower\n",
        "   - Automatic hardware detection: CUDA > MPS > CPU\n",
        "\n",
        "3. **Insufficient memory:**\n",
        "   - WESAD dataset is smaller than Sleep-EDF (~10MB for training)\n",
        "   - LSTM model has ~200K parameters\n",
        "   - Consider smaller batch_size if needed\n",
        "\n",
        "4. **Long training time:**\n",
        "   - First epoch always takes longer (initial loading)\n",
        "   - Logs show progress every 3 batches for DP training\n",
        "   - Early stopping after 10 epochs without improvement\n",
        "\n",
        "5. **Opacus LSTM compatibility:**\n",
        "   - Fixed: Uses DPLSTM instead of nn.LSTM for DP training\n",
        "   - DPLSTM is a drop-in replacement compatible with Opacus\n",
        "   - **Why DPLSTM?** Opacus requires special DP-compatible layers because nn.LSTM uses internal modules that break gradient sampling hooks needed for differential privacy\n",
        "\n",
        "### Model Architecture:\n",
        "- **LSTM**: Bidirectional with 2 layers (64 hidden units)\n",
        "- **Dense**: 2 fully connected layers for classification\n",
        "- **Total**: ~200K parameters\n",
        "\n",
        "### Resources Used:\n",
        "- **GPU**: Recommended for fast training\n",
        "- **RAM**: ~2GB for dataset + model\n",
        "- **Disk**: ~100MB for code + results\n",
        "\n",
        "### Next Steps:\n",
        "1. Compare baseline vs differential privacy performance\n",
        "2. Analyze privacy-utility trade-offs\n",
        "3. Test with other physiological datasets\n",
        "\n",
        "---\n",
        "\n",
        "**Notebook created for SIDM - MHealth Data Privacy project**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
