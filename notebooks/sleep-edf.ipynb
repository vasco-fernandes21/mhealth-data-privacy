{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sleep-EDF PyTorch Training - Google Colab\n",
        "\n",
        "This notebook trains an optimized PyTorch CNN+LSTM model for sleep stage classification using the Sleep-EDF dataset.\n",
        "\n",
        "## Features:\n",
        "- Optimized LSTM model (target: >=87% accuracy)\n",
        "- Efficient data loading for large datasets\n",
        "- Clean logs during training (no emojis)\n",
        "- Early stopping and learning rate scheduling\n",
        "- Memory and speed optimizations\n",
        "- Automatic hardware acceleration (CUDA > MPS > CPU)\n",
        "\n",
        "## Requirements:\n",
        "- Google Colab with GPU enabled\n",
        "- Data in Google Drive: `mydrive/mhealth-data/data/processed/sleep-edf/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Initial Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies from requirements.txt\n",
        "!pip install -r /content/mhealth-data-privacy/requirements.txt\n",
        "\n",
        "# Clone the repository (if not already present)\n",
        "import os\n",
        "if not os.path.exists('/content/mhealth-data-privacy'):\n",
        "    !git clone https://github.com/vasco-fernandes21/mhealth-data-privacy.git\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/mhealth-data-privacy')\n",
        "\n",
        "print(\"Dependencies installed and repository cloned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check if data exists\n",
        "import os\n",
        "data_path = '/content/drive/MyDrive/mhealth-data/data/processed/sleep-edf'\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    print(f\"Data found at: {data_path}\")\n",
        "    \n",
        "    # List files\n",
        "    files = os.listdir(data_path)\n",
        "    print(f\"Available files: {files}\")\n",
        "    \n",
        "    # Check file sizes\n",
        "    for file in ['X_train.npy', 'y_train.npy', 'X_val.npy', 'y_val.npy', 'X_test.npy', 'y_test.npy']:\n",
        "        if file in files:\n",
        "            size = os.path.getsize(os.path.join(data_path, file))\n",
        "            print(f\"  {file}: {size / (1024*1024):.1f} MB\")\n",
        "        else:\n",
        "            print(f\"  {file} not found\")\n",
        "else:\n",
        "    print(f\"Data not found at: {data_path}\")\n",
        "    print(\"Make sure the data is in the correct path on Google Drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training\n",
        "\n",
        "Choose your training option:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option A: Baseline LSTM Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run training using the repository script\n",
        "import os, shutil\n",
        "\n",
        "repo_data_dir = '/content/mhealth-data-privacy/data/processed/sleep-edf'\n",
        "drive_data_dir = '/content/drive/MyDrive/mhealth-data/data/processed/sleep-edf'\n",
        "models_dir = '/content/mhealth-data-privacy/models/sleep-edf/baseline'\n",
        "results_dir = '/content/mhealth-data-privacy/results/sleep-edf/baseline'\n",
        "\n",
        "# Ensure output directories\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Create symbolic link from Drive data to expected path\n",
        "os.makedirs('/content/mhealth-data-privacy/data/processed', exist_ok=True)\n",
        "if os.path.islink(repo_data_dir) or os.path.exists(repo_data_dir):\n",
        "    try:\n",
        "        if os.path.islink(repo_data_dir):\n",
        "            os.unlink(repo_data_dir)\n",
        "        else:\n",
        "            shutil.rmtree(repo_data_dir)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning when removing old destination: {e}\")\n",
        "\n",
        "# Create symlink\n",
        "!ln -sf \"$drive_data_dir\" \"$repo_data_dir\"\n",
        "print(f\"Data referenced via symlink: {repo_data_dir} -> {drive_data_dir}\")\n",
        "\n",
        "print(f\"Starting CNN+LSTM training with data from: {drive_data_dir}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Run the baseline training script\n",
        "!python /content/mhealth-data-privacy/src/train/sleep-edf/train_baseline.py\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option B: Differential Privacy Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run differential privacy training\n",
        "import os, shutil\n",
        "\n",
        "repo_data_dir = '/content/mhealth-data-privacy/data/processed/sleep-edf'\n",
        "drive_data_dir = '/content/drive/MyDrive/mhealth-data/data/processed/sleep-edf'\n",
        "models_dir = '/content/mhealth-data-privacy/models/sleep-edf/dp'\n",
        "results_dir = '/content/mhealth-data-privacy/results/sleep-edf/dp'\n",
        "\n",
        "# Ensure output directories\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "# Create symbolic link from Drive data to expected path\n",
        "os.makedirs('/content/mhealth-data-privacy/data/processed', exist_ok=True)\n",
        "if os.path.islink(repo_data_dir) or os.path.exists(repo_data_dir):\n",
        "    try:\n",
        "        if os.path.islink(repo_data_dir):\n",
        "            os.unlink(repo_data_dir)\n",
        "        else:\n",
        "            shutil.rmtree(repo_data_dir)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning when removing old destination: {e}\")\n",
        "\n",
        "# Create symlink\n",
        "!ln -sf \"$drive_data_dir\" \"$repo_data_dir\"\n",
        "print(f\"Data referenced via symlink: {repo_data_dir} -> {drive_data_dir}\")\n",
        "\n",
        "print(f\"Starting DP training with data from: {drive_data_dir}\")\n",
        "print(\"Using DPLSTM for Opacus compatibility\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Run the DP training script\n",
        "!python /content/mhealth-data-privacy/src/train/sleep-edf/differential_privacy/train_dp.py\n",
        "\n",
        "print(\"Differential privacy training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and analyze results\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Choose which results to load\n",
        "training_type = 'baseline'  # Change to 'dp' for Differential Privacy results\n",
        "\n",
        "if training_type == 'baseline':\n",
        "    results_path = '/content/mhealth-data-privacy/models/sleep-edf/baseline/results_sleep_edf_optimized.json'\n",
        "else:\n",
        "    results_path = '/content/mhealth-data-privacy/models/sleep-edf/dp/results_sleep_edf_dp.json'\n",
        "\n",
        "if os.path.exists(results_path):\n",
        "    with open(results_path, 'r') as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    print(f\"FINAL RESULTS ({training_type.upper()}):\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Accuracy:  {results['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {results['precision']:.4f}\")\n",
        "    print(f\"Recall:    {results['recall']:.4f}\")\n",
        "    print(f\"F1-Score:  {results['f1_score']:.4f}\")\n",
        "    \n",
        "    # If DP, show privacy budget\n",
        "    if training_type == 'dp' and 'dp_params' in results:\n",
        "        print(f\"\\nPrivacy Budget:\")\n",
        "        print(f\"  Epsilon: {results['dp_params']['final_epsilon']:.2f}\")\n",
        "        print(f\"  Delta: {results['dp_params']['delta']:.0e}\")\n",
        "        print(f\"  Noise Multiplier: {results['dp_params']['noise_multiplier']:.2f}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    print(\"\\nCONFUSION MATRIX:\")\n",
        "    cm = np.array(results['confusion_matrix'])\n",
        "    class_names = results['class_names']\n",
        "\n",
        "    print(f\"{'':8s}\", end=\"\")\n",
        "    for name in class_names:\n",
        "        print(f\"{name:8s}\", end=\"\")\n",
        "    print(f\"\\n{'Real ↓':8s}\", end=\"\")\n",
        "\n",
        "    for i, row in enumerate(cm):\n",
        "        print(f\"{class_names[i]:8s}\", end=\"\")\n",
        "        for val in row:\n",
        "            print(f\"{val:8d}\", end=\"\")\n",
        "        print()\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix - Sleep-EDF {training_type.upper()}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(f\"Results not found at: {results_path}\")\n",
        "    print(\"Run the training cell first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Results Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Multiple Runs Experiments\n",
        "\n",
        "This section runs multiple training experiments to ensure robust results:\n",
        "- **Baseline**: 5 runs with different random seeds\n",
        "- **Differential Privacy**: 5 runs with varying noise multipliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Baseline Multiple Runs (5 runs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "# Configuration\n",
        "num_runs = 5\n",
        "seeds = [42, 123, 456, 789, 999]\n",
        "results_baseline = []\n",
        "\n",
        "# Setup directories\n",
        "repo_data_dir = '/content/mhealth-data-privacy/data/processed/sleep-edf'\n",
        "drive_data_dir = '/content/drive/MyDrive/mhealth-data/data/processed/sleep-edf'\n",
        "base_models_dir = '/content/mhealth-data-privacy/models/sleep-edf'\n",
        "base_results_dir = '/content/mhealth-data-privacy/results/sleep-edf'\n",
        "\n",
        "# Create symlink once\n",
        "os.makedirs('/content/mhealth-data-privacy/data/processed', exist_ok=True)\n",
        "if os.path.islink(repo_data_dir) or os.path.exists(repo_data_dir):\n",
        "    try:\n",
        "        if os.path.islink(repo_data_dir):\n",
        "            os.unlink(repo_data_dir)\n",
        "        else:\n",
        "            shutil.rmtree(repo_data_dir)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: {e}\")\n",
        "\n",
        "!ln -sf \"$drive_data_dir\" \"$repo_data_dir\"\n",
        "print(f\"Data linked: {repo_data_dir} -> {drive_data_dir}\\n\")\n",
        "\n",
        "print(\"Starting 5 baseline runs...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for i, seed in enumerate(seeds):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"RUN {i+1}/5 - SEED {seed}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Create run-specific directories\n",
        "    run_dir = f'baseline_run{i+1}'\n",
        "    models_dir = f'{base_models_dir}/{run_dir}'\n",
        "    results_dir = f'{base_results_dir}/{run_dir}'\n",
        "    os.makedirs(models_dir, exist_ok=True)\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "    \n",
        "    # Set environment variables\n",
        "    os.environ['TRAIN_SEED'] = str(seed)\n",
        "    os.environ['MODEL_DIR'] = models_dir\n",
        "    os.environ['RESULTS_DIR'] = results_dir\n",
        "    \n",
        "    # Run training\n",
        "    !python /content/mhealth-data-privacy/src/train/sleep-edf/train_baseline.py\n",
        "    \n",
        "    # Load results\n",
        "    results_path = f'{models_dir}/results_sleep_edf_optimized.json'\n",
        "    if os.path.exists(results_path):\n",
        "        with open(results_path, 'r') as f:\n",
        "            run_results = json.load(f)\n",
        "        \n",
        "        results_baseline.append({\n",
        "            'run': i+1,\n",
        "            'seed': seed,\n",
        "            'accuracy': run_results['accuracy'],\n",
        "            'f1_score': run_results['f1_score'],\n",
        "            'precision': run_results['precision'],\n",
        "            'recall': run_results['recall'],\n",
        "            'confusion_matrix': run_results['confusion_matrix'],\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        \n",
        "        print(f\"\\nRun {i+1} Results: Accuracy={run_results['accuracy']:.4f}, F1={run_results['f1_score']:.4f}\")\n",
        "    else:\n",
        "        print(f\"Warning: Results not found for run {i+1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate statistics and plot results\n",
        "if results_baseline:\n",
        "    # Extract metrics\n",
        "    accuracies = [r['accuracy'] for r in results_baseline]\n",
        "    f1_scores = [r['f1_score'] for r in results_baseline]\n",
        "    precisions = [r['precision'] for r in results_baseline]\n",
        "    recalls = [r['recall'] for r in results_baseline]\n",
        "    \n",
        "    # Calculate mean and std\n",
        "    stats = {\n",
        "        'accuracy': {'mean': np.mean(accuracies), 'std': np.std(accuracies)},\n",
        "        'f1_score': {'mean': np.mean(f1_scores), 'std': np.std(f1_scores)},\n",
        "        'precision': {'mean': np.mean(precisions), 'std': np.std(precisions)},\n",
        "        'recall': {'mean': np.mean(recalls), 'std': np.std(recalls)}\n",
        "    }\n",
        "    \n",
        "    # Plot accuracy and F1 for each run\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Accuracy plot\n",
        "    runs = list(range(1, len(results_baseline) + 1))\n",
        "    axes[0].plot(runs, accuracies, marker='o', linewidth=2, markersize=8, label='Run Accuracy')\n",
        "    axes[0].axhline(stats['accuracy']['mean'], color='red', linestyle='--', label=f\"Mean: {stats['accuracy']['mean']:.4f}\")\n",
        "    axes[0].fill_between(runs, \n",
        "                          stats['accuracy']['mean'] - stats['accuracy']['std'],\n",
        "                          stats['accuracy']['mean'] + stats['accuracy']['std'],\n",
        "                          alpha=0.2, color='red', label=f\"±1 std: {stats['accuracy']['std']:.4f}\")\n",
        "    axes[0].set_xlabel('Run')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].set_title('Accuracy per Run - Sleep-EDF Baseline')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    axes[0].set_xticks(runs)\n",
        "    \n",
        "    # F1-Score plot\n",
        "    axes[1].plot(runs, f1_scores, marker='s', linewidth=2, markersize=8, label='Run F1-Score', color='green')\n",
        "    axes[1].axhline(stats['f1_score']['mean'], color='darkgreen', linestyle='--', label=f\"Mean: {stats['f1_score']['mean']:.4f}\")\n",
        "    axes[1].fill_between(runs,\n",
        "                          stats['f1_score']['mean'] - stats['f1_score']['std'],\n",
        "                          stats['f1_score']['mean'] + stats['f1_score']['std'],\n",
        "                          alpha=0.2, color='green', label=f\"±1 std: {stats['f1_score']['std']:.4f}\")\n",
        "    axes[1].set_xlabel('Run')\n",
        "    axes[1].set_ylabel('F1-Score')\n",
        "    axes[1].set_title('F1-Score per Run - Sleep-EDF Baseline')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    axes[1].set_xticks(runs)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print summary table\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BASELINE MULTIPLE RUNS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Number of runs: {len(results_baseline)}\\n\")\n",
        "    print(f\"Metric        Mean ± Std\")\n",
        "    print(\"-\" * 35)\n",
        "    for metric, values in stats.items():\n",
        "        print(f\"{metric:12s}  {values['mean']:.4f} ± {values['std']:.4f}\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Save summary\n",
        "    summary_path = f'{base_results_dir}/baseline_5runs.json'\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump({'runs': results_baseline, 'statistics': stats}, f, indent=2)\n",
        "    print(f\"\\nSummary saved to: {summary_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Differential Privacy Multiple Runs (5 runs with different noise_multipliers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DP Multiple Runs Configuration\n",
        "noise_multipliers = [0.5, 0.7, 0.9, 1.1, 1.3]\n",
        "results_dp = []\n",
        "\n",
        "print(\"Starting 5 DP runs with different noise multipliers...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, noise_mult in enumerate(noise_multipliers):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"DP RUN {i+1}/5 - NOISE_MULTIPLIER {noise_mult}\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Create run-specific directories\n",
        "    run_dir = f'dp_run{i+1}_noise{noise_mult}'\n",
        "    models_dir = f'{base_models_dir}/{run_dir}'\n",
        "    results_dir = f'{base_results_dir}/{run_dir}'\n",
        "    os.makedirs(models_dir, exist_ok=True)\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "    \n",
        "    # Set environment variables\n",
        "    os.environ['TRAIN_SEED'] = '42'  # Same seed for all DP runs\n",
        "    os.environ['MODEL_DIR'] = models_dir\n",
        "    os.environ['RESULTS_DIR'] = results_dir\n",
        "    os.environ['NOISE_MULTIPLIER'] = str(noise_mult)\n",
        "    \n",
        "    # Run DP training\n",
        "    !python /content/mhealth-data-privacy/src/train/sleep-edf/differential_privacy/train_dp.py\n",
        "    \n",
        "    # Load results\n",
        "    results_path = f'{models_dir}/results_sleep_edf_dp.json'\n",
        "    if os.path.exists(results_path):\n",
        "        with open(results_path, 'r') as f:\n",
        "            run_results = json.load(f)\n",
        "        \n",
        "        # Extract epsilon\n",
        "        epsilon = run_results.get('dp_params', {}).get('final_epsilon', 0.0)\n",
        "        if epsilon == 0.0 and 'epsilon' in run_results:\n",
        "            epsilon = run_results['epsilon']\n",
        "        \n",
        "        results_dp.append({\n",
        "            'run': i+1,\n",
        "            'noise_multiplier': noise_mult,\n",
        "            'epsilon': epsilon,\n",
        "            'accuracy': run_results['accuracy'],\n",
        "            'f1_score': run_results['f1_score'],\n",
        "            'precision': run_results['precision'],\n",
        "            'recall': run_results['recall'],\n",
        "            'confusion_matrix': run_results['confusion_matrix'],\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        })\n",
        "        \n",
        "        print(f\"\\nDP Run {i+1} Results: ε={epsilon:.2f}, Accuracy={run_results['accuracy']:.4f}, F1={run_results['f1_score']:.4f}\")\n",
        "    else:\n",
        "        print(f\"Warning: Results not found for DP run {i+1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate statistics and plot privacy-utility trade-off\n",
        "if results_dp:\n",
        "    # Extract metrics\n",
        "    epsilons = [r['epsilon'] for r in results_dp]\n",
        "    dp_accuracies = [r['accuracy'] for r in results_dp]\n",
        "    dp_f1_scores = [r['f1_score'] for r in results_dp]\n",
        "    dp_precisions = [r['precision'] for r in results_dp]\n",
        "    dp_recalls = [r['recall'] for r in results_dp]\n",
        "    noise_mults = [r['noise_multiplier'] for r in results_dp]\n",
        "    \n",
        "    # Statistics\n",
        "    dp_stats = {\n",
        "        'epsilon_range': {'min': min(epsilons), 'max': max(epsilons)},\n",
        "        'accuracy': {'min': min(dp_accuracies), 'max': max(dp_accuracies)},\n",
        "        'f1_score': {'min': min(dp_f1_scores), 'max': max(dp_f1_scores)},\n",
        "        'precision': {'min': min(dp_precisions), 'max': max(dp_precisions)},\n",
        "        'recall': {'min': min(dp_recalls), 'max': max(dp_recalls)}\n",
        "    }\n",
        "    \n",
        "    # Plot privacy-utility trade-off\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Epsilon vs Accuracy\n",
        "    axes[0].plot(epsilons, dp_accuracies, marker='o', linewidth=2, markersize=8, label='DP Accuracy')\n",
        "    if results_baseline:\n",
        "        axes[0].axhline(stats['accuracy']['mean'], color='red', linestyle='--', \n",
        "                       label=f\"Baseline Mean: {stats['accuracy']['mean']:.4f}\")\n",
        "    for i, (eps, acc, nm) in enumerate(zip(epsilons, dp_accuracies, noise_mults)):\n",
        "        axes[0].annotate(f'σ={nm}', (eps, acc), textcoords=\"offset points\", \n",
        "                        xytext=(0,10), ha='center', fontsize=8)\n",
        "    axes[0].set_xlabel('Privacy Budget (ε)')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].set_title('Privacy-Utility Trade-off: Accuracy - Sleep-EDF')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Epsilon vs F1-Score\n",
        "    axes[1].plot(epsilons, dp_f1_scores, marker='s', linewidth=2, markersize=8, label='DP F1-Score', color='green')\n",
        "    if results_baseline:\n",
        "        axes[1].axhline(stats['f1_score']['mean'], color='darkgreen', linestyle='--',\n",
        "                       label=f\"Baseline Mean: {stats['f1_score']['mean']:.4f}\")\n",
        "    for i, (eps, f1, nm) in enumerate(zip(epsilons, dp_f1_scores, noise_mults)):\n",
        "        axes[1].annotate(f'σ={nm}', (eps, f1), textcoords=\"offset points\",\n",
        "                        xytext=(0,10), ha='center', fontsize=8)\n",
        "    axes[1].set_xlabel('Privacy Budget (ε)')\n",
        "    axes[1].set_ylabel('F1-Score')\n",
        "    axes[1].set_title('Privacy-Utility Trade-off: F1-Score - Sleep-EDF')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print summary table\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DIFFERENTIAL PRIVACY MULTIPLE RUNS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Number of runs: {len(results_dp)}\\n\")\n",
        "    print(f\"Run  Noise σ   ε      Accuracy  F1-Score  Precision  Recall\")\n",
        "    print(\"-\" * 70)\n",
        "    for r in results_dp:\n",
        "        print(f\"{r['run']:3d}  {r['noise_multiplier']:5.1f}  {r['epsilon']:6.2f}  {r['accuracy']:.4f}    {r['f1_score']:.4f}    {r['precision']:.4f}     {r['recall']:.4f}\")\n",
        "    print(\"\\nMetric Ranges:\")\n",
        "    print(\"-\" * 35)\n",
        "    for metric, values in dp_stats.items():\n",
        "        if 'range' in metric:\n",
        "            print(f\"{metric:12s}  [{values['min']:.2f}, {values['max']:.2f}]\")\n",
        "        else:\n",
        "            print(f\"{metric:12s}  [{values['min']:.4f}, {values['max']:.4f}]\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Save summary\n",
        "    summary_path = f'{base_results_dir}/dp_5runs.json'\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump({'runs': results_dp, 'statistics': dp_stats}, f, indent=2)\n",
        "    print(f\"\\nSummary saved to: {summary_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips and Troubleshooting\n",
        "\n",
        "### Common Issues:\n",
        "\n",
        "1. **Data not found:**\n",
        "   - Check if path `mydrive/mhealth-data/data/processed/sleep-edf/` is correct\n",
        "   - Ensure all `.npy` files are present\n",
        "\n",
        "2. **GPU not available:**\n",
        "   - Go to Runtime → Change runtime type → Hardware accelerator → GPU\n",
        "   - Model will work on CPU but will be slower\n",
        "   - Automatic hardware detection: CUDA > MPS > CPU\n",
        "\n",
        "3. **Insufficient memory:**\n",
        "   - Sleep-EDF dataset is large (58MB for training)\n",
        "   - CNN+LSTM model has ~311K parameters\n",
        "   - Consider smaller batch_size if needed\n",
        "\n",
        "4. **Long training time:**\n",
        "   - First epoch always takes longer (initial loading)\n",
        "   - Logs show progress every epoch\n",
        "   - Early stopping after 8 epochs without improvement\n",
        "\n",
        "### Model Architecture:\n",
        "- **CNN**: 3 convolutional blocks for feature extraction\n",
        "- **LSTM**: Bidirectional with 2 layers (64 hidden units)\n",
        "- **Dense**: 3 fully connected layers for classification\n",
        "- **Total**: ~311K parameters\n",
        "\n",
        "### Resources Used:\n",
        "- **GPU**: Recommended for fast training\n",
        "- **RAM**: ~4GB for dataset + model\n",
        "- **Disk**: ~200MB for code + results\n",
        "\n",
        "### Next Steps:\n",
        "1. Compare with simple LSTM baseline (87% accuracy)\n",
        "2. Implement privacy techniques (DP-SGD)\n",
        "3. Test with other physiological datasets\n",
        "\n",
        "---\n",
        "\n",
        "**Notebook created for SIDM - MHealth Data Privacy project**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
