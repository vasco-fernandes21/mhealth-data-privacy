{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab Setup Template\n",
        "\n",
        "Este notebook contém o setup inicial para todos os outros notebooks do projeto.\n",
        "**Execute sempre este setup antes de qualquer outro notebook.**\n",
        "\n",
        "## O que este setup faz:\n",
        "1. Clona o repositório GitHub\n",
        "2. Instala o projeto como package\n",
        "3. Monta o Google Drive\n",
        "4. Configura paths para dados\n",
        "5. Verifica dependências\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 1: Clone GitHub Repository\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CLONING REPOSITORY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Clone the repository \n",
        "!git clone https://github.com/vascofernandes21/mhealth-data-privacy.git\n",
        "%cd mhealth-data-privacy\n",
        "\n",
        "print(\"\\nRepository cloned successfully!\")\n",
        "print(f\"Current directory: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 2: Install Project as Package\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"INSTALLING PROJECT PACKAGE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Install the project as an editable package\n",
        "!pip install -e .\n",
        "\n",
        "print(\"\\nPackage installed successfully!\")\n",
        "print(\"You can now import modules with: from src.models import lstm_baseline\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 3: Mount Google Drive\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MOUNTING GOOGLE DRIVE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\nGoogle Drive mounted successfully!\")\n",
        "print(\"Drive contents available at: /content/drive/MyDrive/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 4: Setup Data Paths\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SETTING UP DATA PATHS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "DRIVE_BASE = '/content/drive/MyDrive/mhealth-data'\n",
        "RAW_DATA_PATH = f'{DRIVE_BASE}/raw'\n",
        "PROCESSED_DATA_PATH = f'{DRIVE_BASE}/processed'\n",
        "MODELS_PATH = f'{DRIVE_BASE}/models'\n",
        "RESULTS_PATH = f'{DRIVE_BASE}/results'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(RAW_DATA_PATH, exist_ok=True)\n",
        "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "# Create symlinks for easy access\n",
        "!ln -sf {DRIVE_BASE} /content/mhealth-data-privacy/data\n",
        "\n",
        "print(f\"\\nData paths configured:\")\n",
        "print(f\"  Raw data: {RAW_DATA_PATH}\")\n",
        "print(f\"  Processed data: {PROCESSED_DATA_PATH}\")\n",
        "print(f\"  Models: {MODELS_PATH}\")\n",
        "print(f\"  Results: {RESULTS_PATH}\")\n",
        "print(f\"\\nSymlink created: /content/mhealth-data-privacy/data -> {DRIVE_BASE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 5: Verify Setup\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"VERIFYING SETUP\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "# Check if we can import our modules\n",
        "try:\n",
        "    from src.preprocessing import sleep_edf, wesad\n",
        "    from src.models import lstm_baseline\n",
        "    from src.privacy import dp_training, fl_training\n",
        "    from src.evaluation import metrics, visualization\n",
        "    print(\"✅ All modules imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Import error: {e}\")\n",
        "\n",
        "# Check Python version\n",
        "print(f\"\\nPython version: {sys.version}\")\n",
        "\n",
        "# Check if GPU is available\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        print(f\"✅ GPU available: {gpus[0].name}\")\n",
        "        # Configure GPU memory growth\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    else:\n",
        "        print(\"⚠️  No GPU available - training will be slower\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ TensorFlow error: {e}\")\n",
        "\n",
        "# Check data directories\n",
        "print(f\"\\nData directory structure:\")\n",
        "if os.path.exists(DRIVE_BASE):\n",
        "    for root, dirs, files in os.walk(DRIVE_BASE):\n",
        "        level = root.replace(DRIVE_BASE, '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files[:5]:  # Show first 5 files\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 5:\n",
        "            print(f\"{subindent}... and {len(files) - 5} more files\")\n",
        "else:\n",
        "    print(f\"⚠️  Data directory not found: {DRIVE_BASE}\")\n",
        "    print(\"   Make sure to create the directory structure in Google Drive\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETUP COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nYou can now run other notebooks or start working with the data.\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Run notebook 01_preprocess_sleep_edf.ipynb (if not done yet)\")\n",
        "print(\"2. Run notebook 02_preprocess_wesad.ipynb (if not done yet)\")\n",
        "print(\"3. Run training notebooks (03, 04, 05)\")\n",
        "print(\"4. Run analysis notebook (06)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
