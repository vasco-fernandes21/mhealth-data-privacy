{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Privacy-Preserving Health Data Analysis\n",
        "\n",
        "Este notebook consolidado executa todo o pipeline de an√°lise de dados de sa√∫de com t√©cnicas de privacidade.\n",
        "\n",
        "## O que este notebook faz:\n",
        "1. **Setup e Mount da Drive** - Configura√ß√£o inicial e montagem do Google Drive\n",
        "2. **Pr√©-processamento** - Processamento dos datasets Sleep-EDF e WESAD\n",
        "3. **Treino Baseline** - Modelos LSTM sem t√©cnicas de privacidade\n",
        "4. **Differential Privacy** - Modelos com privacidade diferencial\n",
        "5. **Federated Learning** - Modelos com aprendizagem federada\n",
        "6. **An√°lise Final** - Compara√ß√£o e visualiza√ß√£o de resultados\n",
        "\n",
        "**‚ö†Ô∏è IMPORTANTE**: Este notebook √© compat√≠vel com Google Colab e Deepnote (com integra√ß√£o da Drive).\n",
        "\n",
        "## Estrutura do Projeto:\n",
        "- **Sleep-EDF**: Classifica√ß√£o de est√°gios do sono (5 classes)\n",
        "- **WESAD**: Detec√ß√£o de stress (2 classes)\n",
        "- **T√©cnicas**: Baseline, DP (Œµ=0.1,1.0,5.0,10.0), FL (3,5,10 clientes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# PARTE 1: SETUP E MOUNT DA DRIVE\n",
        "# ============================================================================\n",
        "\n",
        "## Setup Inicial e Montagem do Google Drive\n",
        "\n",
        "Esta se√ß√£o configura o ambiente e monta o Google Drive para acesso aos dados.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 1: Clone Repository and Install Dependencies\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SETUP INICIAL - PRIVACY-PRESERVING HEALTH DATA ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check if we're already in the project directory\n",
        "if os.path.exists('src') and os.path.exists('requirements.txt'):\n",
        "    print(\"‚úÖ Already in project directory!\")\n",
        "else:\n",
        "    print(\"üì• Cloning repository...\")\n",
        "    \n",
        "    # Clone the repository\n",
        "    try:\n",
        "        result = subprocess.run([\n",
        "            'git', 'clone', \n",
        "            'https://github.com/vasco-fernandes21/mhealth-data-privacy.git'\n",
        "        ], capture_output=True, text=True, check=True)\n",
        "        \n",
        "        print(\"‚úÖ Repository cloned successfully!\")\n",
        "        \n",
        "        # Change to project directory\n",
        "        os.chdir('mhealth-data-privacy')\n",
        "        print(\"üìÅ Changed to project directory\")\n",
        "        \n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå Error cloning repository: {e}\")\n",
        "        print(\"Please clone manually or check the repository URL\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ùå Git not available. Please clone manually:\")\n",
        "        print(\"git clone https://github.com/vasco-fernandes21/mhealth-data-privacy.git\")\n",
        "        print(\"cd mhealth-data-privacy\")\n",
        "\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Install dependencies\n",
        "print(\"\\nüì¶ Installing dependencies...\")\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install the project as an editable package\n",
        "print(\"\\nüì¶ Installing project package...\")\n",
        "!pip install -e .\n",
        "\n",
        "print(\"\\n‚úÖ Dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 2: Mount Google Drive\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MOUNTING GOOGLE DRIVE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"‚úÖ Google Drive mounted successfully!\")\n",
        "\n",
        "# Define data paths in Google Drive\n",
        "DRIVE_BASE = '/content/drive/MyDrive/mhealth-data'\n",
        "RAW_DATA_PATH = f'{DRIVE_BASE}/raw'\n",
        "PROCESSED_DATA_PATH = f'{DRIVE_BASE}/processed'\n",
        "MODELS_PATH = f'{DRIVE_BASE}/models'\n",
        "RESULTS_PATH = f'{DRIVE_BASE}/results'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(RAW_DATA_PATH, exist_ok=True)\n",
        "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
        "os.makedirs(MODELS_PATH, exist_ok=True)\n",
        "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "# Create subdirectories for datasets\n",
        "for dataset in ['sleep-edf', 'wesad']:\n",
        "    os.makedirs(f'{RAW_DATA_PATH}/{dataset}', exist_ok=True)\n",
        "    os.makedirs(f'{PROCESSED_DATA_PATH}/{dataset}', exist_ok=True)\n",
        "    os.makedirs(f'{MODELS_PATH}/{dataset}', exist_ok=True)\n",
        "    os.makedirs(f'{RESULTS_PATH}/{dataset}', exist_ok=True)\n",
        "\n",
        "print(f\"\\nData paths configured:\")\n",
        "print(f\"  Drive base: {DRIVE_BASE}\")\n",
        "print(f\"  Raw data: {RAW_DATA_PATH}\")\n",
        "print(f\"  Processed data: {PROCESSED_DATA_PATH}\")\n",
        "print(f\"  Models: {MODELS_PATH}\")\n",
        "print(f\"  Results: {RESULTS_PATH}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Directory structure created successfully!\")\n",
        "\n",
        "# Make variables globally available\n",
        "globals()['DRIVE_BASE'] = DRIVE_BASE\n",
        "globals()['RAW_DATA_PATH'] = RAW_DATA_PATH\n",
        "globals()['PROCESSED_DATA_PATH'] = PROCESSED_DATA_PATH\n",
        "globals()['MODELS_PATH'] = MODELS_PATH\n",
        "globals()['RESULTS_PATH'] = RESULTS_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 3: Configure Environment\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CONFIGURING ENVIRONMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Check GPU availability\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"‚úÖ GPU available: {gpus[0].name}\")\n",
        "    print(\"   Using GPU for faster training\")\n",
        "    \n",
        "    # Configure GPU memory growth\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        print(\"‚úÖ GPU memory growth configured\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"‚ö†Ô∏è  GPU memory growth configuration failed: {e}\")\n",
        "else:\n",
        "    print(\"üñ•Ô∏è  CPU-only environment detected\")\n",
        "    print(\"   Training will be slower but fully functional\")\n",
        "    print(\"   Expected times: Baseline ~30-60min, DP ~45-90min, FL ~20-40min\")\n",
        "    \n",
        "    # Configure for CPU optimization\n",
        "    tf.config.threading.set_inter_op_parallelism_threads(0)  # Use all available cores\n",
        "    tf.config.threading.set_intra_op_parallelism_threads(0)  # Use all available cores\n",
        "    print(\"‚úÖ CPU threading optimized for all available cores\")\n",
        "\n",
        "print(f\"\\nTensorFlow version: {tf.__version__}\")\n",
        "print(f\"CPU cores available: {os.cpu_count()}\")\n",
        "\n",
        "# Verify imports\n",
        "try:\n",
        "    from src.preprocessing import sleep_edf, wesad\n",
        "    from src.models import lstm_baseline\n",
        "    from src.privacy import dp_training, fl_training\n",
        "    from src.evaluation import metrics, visualization\n",
        "    print(\"‚úÖ All modules imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"   Make sure you ran the installation step above\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SETUP COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nYou can now proceed to data preprocessing.\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Upload raw data to Google Drive\")\n",
        "print(\"2. Run the preprocessing section\")\n",
        "print(\"3. Run the training sections\")\n",
        "print(\"4. Run the analysis section\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# PARTE 2: PR√â-PROCESSAMENTO DOS DADOS\n",
        "# ============================================================================\n",
        "\n",
        "## Processamento dos Datasets Sleep-EDF e WESAD\n",
        "\n",
        "Esta se√ß√£o executa o pr√©-processamento completo dos datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 4: Sleep-EDF Dataset Preprocessing\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SLEEP-EDF PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import our preprocessing module\n",
        "from src.preprocessing.sleep_edf import preprocess_sleep_edf, load_processed_sleep_edf\n",
        "\n",
        "# Define paths\n",
        "SLEEP_RAW_PATH = f'{RAW_DATA_PATH}/sleep-edf'\n",
        "SLEEP_PROCESSED_PATH = f'{PROCESSED_DATA_PATH}/sleep-edf'\n",
        "\n",
        "print(f\"Raw data path: {SLEEP_RAW_PATH}\")\n",
        "print(f\"Processed data path: {SLEEP_PROCESSED_PATH}\")\n",
        "\n",
        "# Check if raw data exists\n",
        "if not os.path.exists(SLEEP_RAW_PATH):\n",
        "    print(f\"‚ùå Raw data directory not found: {SLEEP_RAW_PATH}\")\n",
        "    print(\"Please download Sleep-EDF dataset and place it in the raw directory.\")\n",
        "    print(\"See data/README.md for download instructions.\")\n",
        "else:\n",
        "    print(\"‚úÖ Raw data directory found\")\n",
        "    \n",
        "    # List available files\n",
        "    files = os.listdir(SLEEP_RAW_PATH)\n",
        "    edf_files = [f for f in files if f.endswith('.edf') and not f.endswith('.hyp.edf')]\n",
        "    hyp_files = [f for f in files if f.endswith('.hyp.edf')]\n",
        "    \n",
        "    print(f\"Found {len(edf_files)} recording files and {len(hyp_files)} hypnogram files\")\n",
        "    if edf_files:\n",
        "        print(\"Sample files:\", edf_files[:3])\n",
        "\n",
        "# Run preprocessing if data is available\n",
        "if os.path.exists(SLEEP_RAW_PATH) and len(edf_files) > 0:\n",
        "    print(\"\\nStarting Sleep-EDF preprocessing...\")\n",
        "    \n",
        "    # Run preprocessing\n",
        "    preprocessing_info = preprocess_sleep_edf(\n",
        "        data_dir=SLEEP_RAW_PATH,\n",
        "        output_dir=SLEEP_PROCESSED_PATH,\n",
        "        test_size=0.15,\n",
        "        val_size=0.15,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SLEEP-EDF PREPROCESSING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Preprocessing info: {preprocessing_info}\")\n",
        "    \n",
        "    # Verify processed data\n",
        "    if os.path.exists(SLEEP_PROCESSED_PATH):\n",
        "        print(\"\\nVerifying processed data...\")\n",
        "        \n",
        "        # Load processed data to verify\n",
        "        X_train_sleep, X_val_sleep, X_test_sleep, y_train_sleep, y_val_sleep, y_test_sleep, scaler_sleep, label_encoder_sleep, sleep_info = load_processed_sleep_edf(SLEEP_PROCESSED_PATH)\n",
        "        \n",
        "        print(f\"\\nData shapes:\")\n",
        "        print(f\"  Train: {X_train_sleep.shape}\")\n",
        "        print(f\"  Val:   {X_val_sleep.shape}\")\n",
        "        print(f\"  Test:  {X_test_sleep.shape}\")\n",
        "        \n",
        "        print(f\"\\nLabel distribution:\")\n",
        "        print(f\"  Train: {np.bincount(y_train_sleep)}\")\n",
        "        print(f\"  Val:   {np.bincount(y_val_sleep)}\")\n",
        "        print(f\"  Test:  {np.bincount(y_test_sleep)}\")\n",
        "        \n",
        "        print(f\"\\nClass names: {sleep_info['class_names']}\")\n",
        "        print(f\"Features per sample: {sleep_info['n_features']}\")\n",
        "        \n",
        "        print(\"\\n‚úÖ Sleep-EDF preprocessing completed successfully!\")\n",
        "        print(\"Data is ready for training models.\")\n",
        "        \n",
        "        # Make data globally available\n",
        "        globals()['X_train_sleep'] = X_train_sleep\n",
        "        globals()['X_val_sleep'] = X_val_sleep\n",
        "        globals()['X_test_sleep'] = X_test_sleep\n",
        "        globals()['y_train_sleep'] = y_train_sleep\n",
        "        globals()['y_val_sleep'] = y_val_sleep\n",
        "        globals()['y_test_sleep'] = y_test_sleep\n",
        "        globals()['sleep_info'] = sleep_info\n",
        "        \n",
        "else:\n",
        "    print(\"‚ùå Cannot proceed without raw data files\")\n",
        "    print(\"Please download the Sleep-EDF dataset first.\")\n",
        "    # Set to None for later checks\n",
        "    X_train_sleep = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 5: WESAD Dataset Preprocessing\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"WESAD PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import our preprocessing module\n",
        "from src.preprocessing.wesad import preprocess_wesad, load_processed_wesad\n",
        "\n",
        "# Define paths\n",
        "WESAD_RAW_PATH = f'{RAW_DATA_PATH}/wesad'\n",
        "WESAD_PROCESSED_PATH = f'{PROCESSED_DATA_PATH}/wesad'\n",
        "\n",
        "print(f\"Raw data path: {WESAD_RAW_PATH}\")\n",
        "print(f\"Processed data path: {WESAD_PROCESSED_PATH}\")\n",
        "\n",
        "# Check if raw data exists\n",
        "if not os.path.exists(WESAD_RAW_PATH):\n",
        "    print(f\"‚ùå Raw data directory not found: {WESAD_RAW_PATH}\")\n",
        "    print(\"Please download WESAD dataset and place it in the raw directory.\")\n",
        "    print(\"See data/README.md for download instructions.\")\n",
        "else:\n",
        "    print(\"‚úÖ Raw data directory found\")\n",
        "    \n",
        "    # List available files\n",
        "    files = os.listdir(WESAD_RAW_PATH)\n",
        "    pkl_files = [f for f in files if f.endswith('.pkl')]\n",
        "    \n",
        "    print(f\"Found {len(pkl_files)} pickle files\")\n",
        "    if pkl_files:\n",
        "        print(\"Sample files:\", pkl_files[:3])\n",
        "\n",
        "# Run preprocessing if data is available\n",
        "if os.path.exists(WESAD_RAW_PATH) and len(pkl_files) > 0:\n",
        "    print(\"\\nStarting WESAD preprocessing...\")\n",
        "    \n",
        "    # Run preprocessing\n",
        "    preprocessing_info = preprocess_wesad(\n",
        "        data_dir=WESAD_RAW_PATH,\n",
        "        output_dir=WESAD_PROCESSED_PATH,\n",
        "        test_size=0.15,\n",
        "        val_size=0.15,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"WESAD PREPROCESSING COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Preprocessing info: {preprocessing_info}\")\n",
        "    \n",
        "    # Verify processed data\n",
        "    if os.path.exists(WESAD_PROCESSED_PATH):\n",
        "        print(\"\\nVerifying processed data...\")\n",
        "        \n",
        "        # Load processed data to verify\n",
        "        X_train_wesad, X_val_wesad, X_test_wesad, y_train_wesad, y_val_wesad, y_test_wesad, scaler_wesad, label_encoder_wesad, wesad_info = load_processed_wesad(WESAD_PROCESSED_PATH)\n",
        "        \n",
        "        print(f\"\\nData shapes:\")\n",
        "        print(f\"  Train: {X_train_wesad.shape}\")\n",
        "        print(f\"  Val:   {X_val_wesad.shape}\")\n",
        "        print(f\"  Test:  {X_test_wesad.shape}\")\n",
        "        \n",
        "        print(f\"\\nLabel distribution:\")\n",
        "        print(f\"  Train: {np.bincount(y_train_wesad)}\")\n",
        "        print(f\"  Val:   {np.bincount(y_val_wesad)}\")\n",
        "        print(f\"  Test:  {np.bincount(y_test_wesad)}\")\n",
        "        \n",
        "        print(f\"\\nClass names: {wesad_info['class_names']}\")\n",
        "        print(f\"Features per sample: {wesad_info['n_features']}\")\n",
        "        print(f\"Original labels: {wesad_info['original_labels']}\")\n",
        "        print(f\"Filtered labels: {wesad_info['filtered_labels']}\")\n",
        "        \n",
        "        print(\"\\n‚úÖ WESAD preprocessing completed successfully!\")\n",
        "        print(\"Data is ready for training models.\")\n",
        "        \n",
        "        # Make data globally available\n",
        "        globals()['X_train_wesad'] = X_train_wesad\n",
        "        globals()['X_val_wesad'] = X_val_wesad\n",
        "        globals()['X_test_wesad'] = X_test_wesad\n",
        "        globals()['y_train_wesad'] = y_train_wesad\n",
        "        globals()['y_val_wesad'] = y_val_wesad\n",
        "        globals()['y_test_wesad'] = y_test_wesad\n",
        "        globals()['wesad_info'] = wesad_info\n",
        "        \n",
        "else:\n",
        "    print(\"‚ùå Cannot proceed without raw data files\")\n",
        "    print(\"Please download the WESAD dataset first.\")\n",
        "    # Set to None for later checks\n",
        "    X_train_wesad = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# PARTE 3: TREINO DE MODELOS BASELINE\n",
        "# ============================================================================\n",
        "\n",
        "## Modelos LSTM Baseline (sem t√©cnicas de privacidade)\n",
        "\n",
        "Esta se√ß√£o treina modelos LSTM baseline para ambos os datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 6: Train Sleep-EDF Baseline Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"LSTM BASELINE TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import modules\n",
        "from src.models.lstm_baseline import train_baseline, evaluate_model, save_model, get_default_config\n",
        "from src.evaluation.visualization import plot_training_history\n",
        "\n",
        "# Check if Sleep-EDF data is available\n",
        "if 'X_train_sleep' in globals() and X_train_sleep is not None:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING SLEEP-EDF BASELINE MODEL\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Get default configuration\n",
        "    config = get_default_config()\n",
        "    config.update({\n",
        "        'dataset': 'sleep_edf',\n",
        "        'model_type': 'baseline',\n",
        "        'privacy_technique': 'None'\n",
        "    })\n",
        "    \n",
        "    print(f\"Configuration: {config}\")\n",
        "    \n",
        "    # Train model\n",
        "    model_sleep, history_sleep = train_baseline(\n",
        "        X_train_sleep, y_train_sleep,\n",
        "        X_val_sleep, y_val_sleep,\n",
        "        config\n",
        "    )\n",
        "    \n",
        "    # Evaluate model\n",
        "    results_sleep = evaluate_model(model_sleep, X_test_sleep, y_test_sleep, config['window_size'])\n",
        "    results_sleep.update({\n",
        "        'dataset': 'sleep_edf',\n",
        "        'model_type': 'baseline',\n",
        "        'privacy_technique': 'None',\n",
        "        'privacy_parameter': 'N/A'\n",
        "    })\n",
        "    \n",
        "    # Save model and results\n",
        "    save_model(\n",
        "        model_sleep, history_sleep, results_sleep,\n",
        "        MODELS_PATH, 'sleep_edf_baseline'\n",
        "    )\n",
        "    \n",
        "    # Save training history plot\n",
        "    plot_training_history(\n",
        "        history_sleep.history,\n",
        "        save_path=f'{RESULTS_PATH}/training_history_sleep_edf_baseline.png',\n",
        "        title='Sleep-EDF Baseline Training History'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úÖ Sleep-EDF baseline model trained successfully!\")\n",
        "    print(f\"Test Accuracy: {results_sleep['accuracy']:.4f}\")\n",
        "    print(f\"Test F1-Score: {results_sleep['f1_score']:.4f}\")\n",
        "    \n",
        "    # Make results globally available\n",
        "    globals()['results_sleep'] = results_sleep\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Skipping Sleep-EDF training - data not available\")\n",
        "    print(\"Please run the preprocessing section first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 7: Train WESAD Baseline Model\n",
        "# ============================================================================\n",
        "\n",
        "# Check if WESAD data is available\n",
        "if 'X_train_wesad' in globals() and X_train_wesad is not None:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING WESAD BASELINE MODEL\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Get default configuration\n",
        "    config = get_default_config()\n",
        "    config.update({\n",
        "        'dataset': 'wesad',\n",
        "        'model_type': 'baseline',\n",
        "        'privacy_technique': 'None'\n",
        "    })\n",
        "    \n",
        "    print(f\"Configuration: {config}\")\n",
        "    \n",
        "    # Train model\n",
        "    model_wesad, history_wesad = train_baseline(\n",
        "        X_train_wesad, y_train_wesad,\n",
        "        X_val_wesad, y_val_wesad,\n",
        "        config\n",
        "    )\n",
        "    \n",
        "    # Evaluate model\n",
        "    results_wesad = evaluate_model(model_wesad, X_test_wesad, y_test_wesad, config['window_size'])\n",
        "    results_wesad.update({\n",
        "        'dataset': 'wesad',\n",
        "        'model_type': 'baseline',\n",
        "        'privacy_technique': 'None',\n",
        "        'privacy_parameter': 'N/A'\n",
        "    })\n",
        "    \n",
        "    # Save model and results\n",
        "    save_model(\n",
        "        model_wesad, history_wesad, results_wesad,\n",
        "        MODELS_PATH, 'wesad_baseline'\n",
        "    )\n",
        "    \n",
        "    # Save training history plot\n",
        "    plot_training_history(\n",
        "        history_wesad.history,\n",
        "        save_path=f'{RESULTS_PATH}/training_history_wesad_baseline.png',\n",
        "        title='WESAD Baseline Training History'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úÖ WESAD baseline model trained successfully!\")\n",
        "    print(f\"Test Accuracy: {results_wesad['accuracy']:.4f}\")\n",
        "    print(f\"Test F1-Score: {results_wesad['f1_score']:.4f}\")\n",
        "    \n",
        "    # Make results globally available\n",
        "    globals()['results_wesad'] = results_wesad\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Skipping WESAD training - data not available\")\n",
        "    print(\"Please run the preprocessing section first.\")\n",
        "\n",
        "# Summary of baseline training\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BASELINE TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Collect all results\n",
        "all_baseline_results = {}\n",
        "\n",
        "if 'results_sleep' in globals():\n",
        "    all_baseline_results['Sleep-EDF Baseline'] = results_sleep\n",
        "    print(f\"Sleep-EDF Baseline - Accuracy: {results_sleep['accuracy']:.4f}, F1: {results_sleep['f1_score']:.4f}\")\n",
        "\n",
        "if 'results_wesad' in globals():\n",
        "    all_baseline_results['WESAD Baseline'] = results_wesad\n",
        "    print(f\"WESAD Baseline - Accuracy: {results_wesad['accuracy']:.4f}, F1: {results_wesad['f1_score']:.4f}\")\n",
        "\n",
        "# Save combined results\n",
        "if all_baseline_results:\n",
        "    from src.evaluation.metrics import save_evaluation_results\n",
        "    save_evaluation_results(all_baseline_results, RESULTS_PATH, 'baseline_results.json')\n",
        "\n",
        "print(f\"\\nModels saved to: {MODELS_PATH}\")\n",
        "print(f\"Results saved to: {RESULTS_PATH}\")\n",
        "\n",
        "print(\"\\n‚úÖ Baseline models are ready for comparison with privacy-preserving techniques!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# PARTE 4: DIFFERENTIAL PRIVACY TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "## Modelos LSTM com Differential Privacy\n",
        "\n",
        "Esta se√ß√£o treina modelos LSTM com Differential Privacy para diferentes valores de epsilon.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 8: Train Sleep-EDF DP Models\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DIFFERENTIAL PRIVACY TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import modules\n",
        "from src.privacy.dp_training import train_with_dp, evaluate_dp_model, save_dp_model, get_dp_configs\n",
        "from src.evaluation.visualization import plot_tradeoff_curve\n",
        "\n",
        "# Define epsilon values to test\n",
        "epsilon_values = [0.1, 1.0, 5.0, 10.0]\n",
        "print(f\"\\nEpsilon values to test: {epsilon_values}\")\n",
        "\n",
        "# Train Sleep-EDF DP models\n",
        "if 'X_train_sleep' in globals() and X_train_sleep is not None:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING SLEEP-EDF DP MODELS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    sleep_dp_results = {}\n",
        "    \n",
        "    for epsilon in epsilon_values:\n",
        "        print(f\"\\n--- Training with epsilon = {epsilon} ---\")\n",
        "        \n",
        "        # Get DP configuration\n",
        "        dp_configs = get_dp_configs([epsilon])\n",
        "        config = dp_configs[0]\n",
        "        config.update({\n",
        "            'dataset': 'sleep_edf',\n",
        "            'model_type': 'dp',\n",
        "            'privacy_technique': 'DP',\n",
        "            'privacy_parameter': f'Œµ={epsilon}'\n",
        "        })\n",
        "        \n",
        "        # Train DP model\n",
        "        model_dp, history_dp, privacy_info = train_with_dp(\n",
        "            X_train_sleep, y_train_sleep,\n",
        "            X_val_sleep, y_val_sleep,\n",
        "            config\n",
        "        )\n",
        "        \n",
        "        # Evaluate model\n",
        "        results_dp = evaluate_dp_model(model_dp, X_test_sleep, y_test_sleep, config['window_size'])\n",
        "        results_dp.update({\n",
        "            'dataset': 'sleep_edf',\n",
        "            'model_type': 'dp',\n",
        "            'privacy_technique': 'DP',\n",
        "            'privacy_parameter': f'Œµ={epsilon}',\n",
        "            'epsilon': epsilon,\n",
        "            'epsilon_actual': privacy_info['epsilon_actual']\n",
        "        })\n",
        "        \n",
        "        # Save model and results\n",
        "        model_name = f'sleep_edf_dp_epsilon_{epsilon}'\n",
        "        save_dp_model(\n",
        "            model_dp, history_dp, results_dp, privacy_info,\n",
        "            MODELS_PATH, model_name\n",
        "        )\n",
        "        \n",
        "        # Store results\n",
        "        sleep_dp_results[f'Sleep-EDF DP (Œµ={epsilon})'] = results_dp\n",
        "        \n",
        "        print(f\"‚úÖ Sleep-EDF DP model (Œµ={epsilon}) trained successfully!\")\n",
        "        print(f\"Test Accuracy: {results_dp['accuracy']:.4f}\")\n",
        "        print(f\"Actual Epsilon: {privacy_info['epsilon_actual']:.4f}\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ All Sleep-EDF DP models trained!\")\n",
        "    \n",
        "    # Make results globally available\n",
        "    globals()['sleep_dp_results'] = sleep_dp_results\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Skipping Sleep-EDF DP training - data not available\")\n",
        "    sleep_dp_results = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 9: Train WESAD DP Models\n",
        "# ============================================================================\n",
        "\n",
        "# Train WESAD DP models\n",
        "if 'X_train_wesad' in globals() and X_train_wesad is not None:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING WESAD DP MODELS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    wesad_dp_results = {}\n",
        "    \n",
        "    for epsilon in epsilon_values:\n",
        "        print(f\"\\n--- Training with epsilon = {epsilon} ---\")\n",
        "        \n",
        "        # Get DP configuration\n",
        "        dp_configs = get_dp_configs([epsilon])\n",
        "        config = dp_configs[0]\n",
        "        config.update({\n",
        "            'dataset': 'wesad',\n",
        "            'model_type': 'dp',\n",
        "            'privacy_technique': 'DP',\n",
        "            'privacy_parameter': f'Œµ={epsilon}'\n",
        "        })\n",
        "        \n",
        "        # Train DP model\n",
        "        model_dp, history_dp, privacy_info = train_with_dp(\n",
        "            X_train_wesad, y_train_wesad,\n",
        "            X_val_wesad, y_val_wesad,\n",
        "            config\n",
        "        )\n",
        "        \n",
        "        # Evaluate model\n",
        "        results_dp = evaluate_dp_model(model_dp, X_test_wesad, y_test_wesad, config['window_size'])\n",
        "        results_dp.update({\n",
        "            'dataset': 'wesad',\n",
        "            'model_type': 'dp',\n",
        "            'privacy_technique': 'DP',\n",
        "            'privacy_parameter': f'Œµ={epsilon}',\n",
        "            'epsilon': epsilon,\n",
        "            'epsilon_actual': privacy_info['epsilon_actual']\n",
        "        })\n",
        "        \n",
        "        # Save model and results\n",
        "        model_name = f'wesad_dp_epsilon_{epsilon}'\n",
        "        save_dp_model(\n",
        "            model_dp, history_dp, results_dp, privacy_info,\n",
        "            MODELS_PATH, model_name\n",
        "        )\n",
        "        \n",
        "        # Store results\n",
        "        wesad_dp_results[f'WESAD DP (Œµ={epsilon})'] = results_dp\n",
        "        \n",
        "        print(f\"‚úÖ WESAD DP model (Œµ={epsilon}) trained successfully!\")\n",
        "        print(f\"Test Accuracy: {results_dp['accuracy']:.4f}\")\n",
        "        print(f\"Actual Epsilon: {privacy_info['epsilon_actual']:.4f}\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ All WESAD DP models trained!\")\n",
        "    \n",
        "    # Make results globally available\n",
        "    globals()['wesad_dp_results'] = wesad_dp_results\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Skipping WESAD DP training - data not available\")\n",
        "    wesad_dp_results = {}\n",
        "\n",
        "# Create DP trade-off visualizations\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING DP TRADE-OFF VISUALIZATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Combine all DP results\n",
        "all_dp_results = {}\n",
        "all_dp_results.update(sleep_dp_results)\n",
        "all_dp_results.update(wesad_dp_results)\n",
        "\n",
        "if all_dp_results:\n",
        "    # Create trade-off curve for Sleep-EDF\n",
        "    if sleep_dp_results:\n",
        "        plot_tradeoff_curve(\n",
        "            sleep_dp_results,\n",
        "            metric='accuracy',\n",
        "            privacy_param='epsilon',\n",
        "            save_path=f'{RESULTS_PATH}/dp_tradeoff_sleep_edf.png',\n",
        "            title='Sleep-EDF: Privacy vs. Performance Trade-off'\n",
        "        )\n",
        "    \n",
        "    # Create trade-off curve for WESAD\n",
        "    if wesad_dp_results:\n",
        "        plot_tradeoff_curve(\n",
        "            wesad_dp_results,\n",
        "            metric='accuracy',\n",
        "            privacy_param='epsilon',\n",
        "            save_path=f'{RESULTS_PATH}/dp_tradeoff_wesad.png',\n",
        "            title='WESAD: Privacy vs. Performance Trade-off'\n",
        "        )\n",
        "    \n",
        "    # Save all DP results\n",
        "    from src.evaluation.metrics import save_evaluation_results\n",
        "    save_evaluation_results(all_dp_results, RESULTS_PATH, 'dp_results.json')\n",
        "    \n",
        "    print(\"‚úÖ DP visualizations created and results saved!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No DP results to visualize\")\n",
        "\n",
        "# Summary of DP training\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DP TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Print summary\n",
        "if sleep_dp_results:\n",
        "    print(\"\\nSleep-EDF DP Results:\")\n",
        "    for model_name, results in sleep_dp_results.items():\n",
        "        print(f\"  {model_name}: Accuracy={results['accuracy']:.4f}, F1={results['f1_score']:.4f}, Œµ={results['epsilon_actual']:.4f}\")\n",
        "\n",
        "if wesad_dp_results:\n",
        "    print(\"\\nWESAD DP Results:\")\n",
        "    for model_name, results in wesad_dp_results.items():\n",
        "        print(f\"  {model_name}: Accuracy={results['accuracy']:.4f}, F1={results['f1_score']:.4f}, Œµ={results['epsilon_actual']:.4f}\")\n",
        "\n",
        "print(f\"\\nModels saved to: {MODELS_PATH}\")\n",
        "print(f\"Results saved to: {RESULTS_PATH}\")\n",
        "\n",
        "print(\"\\n‚úÖ DP models are ready for comparison with baseline and FL approaches!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# PARTE 5: FEDERATED LEARNING TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "## Modelos LSTM com Federated Learning\n",
        "\n",
        "Esta se√ß√£o treina modelos LSTM com Federated Learning para diferentes n√∫meros de clientes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 10: Train Sleep-EDF FL Models\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FEDERATED LEARNING TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import modules\n",
        "from src.privacy.fl_training import train_with_fl, evaluate_fl_model, save_fl_model, get_fl_configs\n",
        "from src.evaluation.visualization import plot_fl_convergence, plot_comparison_bars\n",
        "\n",
        "# Define client numbers to test\n",
        "n_clients_list = [3, 5, 10]\n",
        "print(f\"\\nClient numbers to test: {n_clients_list}\")\n",
        "\n",
        "# Train Sleep-EDF FL models\n",
        "if 'X_train_sleep' in globals() and X_train_sleep is not None:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING SLEEP-EDF FL MODELS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    sleep_fl_results = {}\n",
        "    \n",
        "    for n_clients in n_clients_list:\n",
        "        print(f\"\\n--- Training with {n_clients} clients ---\")\n",
        "        \n",
        "        # Get FL configuration\n",
        "        fl_configs = get_fl_configs([n_clients])\n",
        "        config = fl_configs[0]\n",
        "        config.update({\n",
        "            'dataset': 'sleep_edf',\n",
        "            'model_type': 'fl',\n",
        "            'privacy_technique': 'FL',\n",
        "            'privacy_parameter': f'{n_clients} clients'\n",
        "        })\n",
        "        \n",
        "        # Train FL model\n",
        "        model_fl, history_fl, fl_info = train_with_fl(\n",
        "            X_train_sleep, y_train_sleep,\n",
        "            X_val_sleep, y_val_sleep,\n",
        "            config\n",
        "        )\n",
        "        \n",
        "        # Evaluate model\n",
        "        results_fl = evaluate_fl_model(model_fl, X_test_sleep, y_test_sleep, config['window_size'])\n",
        "        results_fl.update({\n",
        "            'dataset': 'sleep_edf',\n",
        "            'model_type': 'fl',\n",
        "            'privacy_technique': 'FL',\n",
        "            'privacy_parameter': f'{n_clients} clients',\n",
        "            'n_clients': n_clients,\n",
        "            'communication_cost': fl_info['communication_cost']\n",
        "        })\n",
        "        \n",
        "        # Save model and results\n",
        "        model_name = f'sleep_edf_fl_{n_clients}_clients'\n",
        "        save_fl_model(\n",
        "            model_fl, history_fl, results_fl, fl_info,\n",
        "            MODELS_PATH, model_name\n",
        "        )\n",
        "        \n",
        "        # Store results\n",
        "        sleep_fl_results[f'Sleep-EDF FL ({n_clients} clients)'] = results_fl\n",
        "        \n",
        "        print(f\"‚úÖ Sleep-EDF FL model ({n_clients} clients) trained successfully!\")\n",
        "        print(f\"Test Accuracy: {results_fl['accuracy']:.4f}\")\n",
        "        print(f\"Communication Cost: {fl_info['communication_cost']} rounds\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ All Sleep-EDF FL models trained!\")\n",
        "    \n",
        "    # Make results globally available\n",
        "    globals()['sleep_fl_results'] = sleep_fl_results\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Skipping Sleep-EDF FL training - data not available\")\n",
        "    sleep_fl_results = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 11: Train WESAD FL Models\n",
        "# ============================================================================\n",
        "\n",
        "# Train WESAD FL models\n",
        "if 'X_train_wesad' in globals() and X_train_wesad is not None:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TRAINING WESAD FL MODELS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    wesad_fl_results = {}\n",
        "    \n",
        "    for n_clients in n_clients_list:\n",
        "        print(f\"\\n--- Training with {n_clients} clients ---\")\n",
        "        \n",
        "        # Get FL configuration\n",
        "        fl_configs = get_fl_configs([n_clients])\n",
        "        config = fl_configs[0]\n",
        "        config.update({\n",
        "            'dataset': 'wesad',\n",
        "            'model_type': 'fl',\n",
        "            'privacy_technique': 'FL',\n",
        "            'privacy_parameter': f'{n_clients} clients'\n",
        "        })\n",
        "        \n",
        "        # Train FL model\n",
        "        model_fl, history_fl, fl_info = train_with_fl(\n",
        "            X_train_wesad, y_train_wesad,\n",
        "            X_val_wesad, y_val_wesad,\n",
        "            config\n",
        "        )\n",
        "        \n",
        "        # Evaluate model\n",
        "        results_fl = evaluate_fl_model(model_fl, X_test_wesad, y_test_wesad, config['window_size'])\n",
        "        results_fl.update({\n",
        "            'dataset': 'wesad',\n",
        "            'model_type': 'fl',\n",
        "            'privacy_technique': 'FL',\n",
        "            'privacy_parameter': f'{n_clients} clients',\n",
        "            'n_clients': n_clients,\n",
        "            'communication_cost': fl_info['communication_cost']\n",
        "        })\n",
        "        \n",
        "        # Save model and results\n",
        "        model_name = f'wesad_fl_{n_clients}_clients'\n",
        "        save_fl_model(\n",
        "            model_fl, history_fl, results_fl, fl_info,\n",
        "            MODELS_PATH, model_name\n",
        "        )\n",
        "        \n",
        "        # Store results\n",
        "        wesad_fl_results[f'WESAD FL ({n_clients} clients)'] = results_fl\n",
        "        \n",
        "        print(f\"‚úÖ WESAD FL model ({n_clients} clients) trained successfully!\")\n",
        "        print(f\"Test Accuracy: {results_fl['accuracy']:.4f}\")\n",
        "        print(f\"Communication Cost: {fl_info['communication_cost']} rounds\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ All WESAD FL models trained!\")\n",
        "    \n",
        "    # Make results globally available\n",
        "    globals()['wesad_fl_results'] = wesad_fl_results\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Skipping WESAD FL training - data not available\")\n",
        "    wesad_fl_results = {}\n",
        "\n",
        "# Create FL visualizations\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING FL VISUALIZATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Combine all FL results\n",
        "all_fl_results = {}\n",
        "all_fl_results.update(sleep_fl_results)\n",
        "all_fl_results.update(wesad_fl_results)\n",
        "\n",
        "if all_fl_results:\n",
        "    # Create comparison bars for Sleep-EDF\n",
        "    if sleep_fl_results:\n",
        "        plot_comparison_bars(\n",
        "            sleep_fl_results,\n",
        "            metrics=['accuracy', 'f1_score'],\n",
        "            save_path=f'{RESULTS_PATH}/fl_comparison_sleep_edf.png',\n",
        "            title='Sleep-EDF: FL Performance Comparison'\n",
        "        )\n",
        "    \n",
        "    # Create comparison bars for WESAD\n",
        "    if wesad_fl_results:\n",
        "        plot_comparison_bars(\n",
        "            wesad_fl_results,\n",
        "            metrics=['accuracy', 'f1_score'],\n",
        "            save_path=f'{RESULTS_PATH}/fl_comparison_wesad.png',\n",
        "            title='WESAD: FL Performance Comparison'\n",
        "        )\n",
        "    \n",
        "    # Save all FL results\n",
        "    from src.evaluation.metrics import save_evaluation_results\n",
        "    save_evaluation_results(all_fl_results, RESULTS_PATH, 'fl_results.json')\n",
        "    \n",
        "    print(\"‚úÖ FL visualizations created and results saved!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No FL results to visualize\")\n",
        "\n",
        "# Summary of FL training\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FL TRAINING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Print summary\n",
        "if sleep_fl_results:\n",
        "    print(\"\\nSleep-EDF FL Results:\")\n",
        "    for model_name, results in sleep_fl_results.items():\n",
        "        print(f\"  {model_name}: Accuracy={results['accuracy']:.4f}, F1={results['f1_score']:.4f}, Cost={results['communication_cost']}\")\n",
        "\n",
        "if wesad_fl_results:\n",
        "    print(\"\\nWESAD FL Results:\")\n",
        "    for model_name, results in wesad_fl_results.items():\n",
        "        print(f\"  {model_name}: Accuracy={results['accuracy']:.4f}, F1={results['f1_score']:.4f}, Cost={results['communication_cost']}\")\n",
        "\n",
        "print(f\"\\nModels saved to: {MODELS_PATH}\")\n",
        "print(f\"Results saved to: {RESULTS_PATH}\")\n",
        "\n",
        "print(\"\\n‚úÖ FL models are ready for final analysis and comparison!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ============================================================================\n",
        "# PARTE 6: AN√ÅLISE FINAL E COMPARA√á√ÉO\n",
        "# ============================================================================\n",
        "\n",
        "## An√°lise Abrangente de Resultados\n",
        "\n",
        "Esta se√ß√£o realiza a an√°lise final comparando todas as abordagens: Baseline, Differential Privacy e Federated Learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 12: Load All Results and Create Comprehensive Analysis\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COMPREHENSIVE ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Import modules\n",
        "from src.evaluation.metrics import load_evaluation_results, compare_models, create_results_summary\n",
        "from src.evaluation.visualization import (\n",
        "    plot_tradeoff_curve, plot_comparison_bars, plot_privacy_analysis,\n",
        "    create_summary_dashboard\n",
        ")\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "print(\"Loading all results...\")\n",
        "\n",
        "# Load baseline results\n",
        "baseline_results = {}\n",
        "if os.path.exists(f'{RESULTS_PATH}/baseline_results.json'):\n",
        "    baseline_results = load_evaluation_results(f'{RESULTS_PATH}/baseline_results.json')\n",
        "    print(f\"‚úÖ Baseline results loaded: {len(baseline_results)} models\")\n",
        "\n",
        "# Load DP results\n",
        "dp_results = {}\n",
        "if os.path.exists(f'{RESULTS_PATH}/dp_results.json'):\n",
        "    dp_results = load_evaluation_results(f'{RESULTS_PATH}/dp_results.json')\n",
        "    print(f\"‚úÖ DP results loaded: {len(dp_results)} models\")\n",
        "\n",
        "# Load FL results\n",
        "fl_results = {}\n",
        "if os.path.exists(f'{RESULTS_PATH}/fl_results.json'):\n",
        "    fl_results = load_evaluation_results(f'{RESULTS_PATH}/fl_results.json')\n",
        "    print(f\"‚úÖ FL results loaded: {len(fl_results)} models\")\n",
        "\n",
        "# Combine all results\n",
        "all_results = {}\n",
        "all_results.update(baseline_results)\n",
        "all_results.update(dp_results)\n",
        "all_results.update(fl_results)\n",
        "\n",
        "print(f\"\\nTotal models analyzed: {len(all_results)}\")\n",
        "print(f\"Techniques: {set([results.get('privacy_technique', 'Unknown') for results in all_results.values()])}\")\n",
        "\n",
        "# Create comprehensive summary\n",
        "if all_results:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Create comprehensive summary\n",
        "    summary_df = create_results_summary(all_results, f'{RESULTS_PATH}/comprehensive_results_summary.csv')\n",
        "    \n",
        "    print(\"Results Summary Table:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "    \n",
        "    # Save detailed summary\n",
        "    summary_df.to_csv(f'{RESULTS_PATH}/detailed_results_summary.csv', index=False)\n",
        "    print(f\"\\n‚úÖ Detailed summary saved to: {RESULTS_PATH}/detailed_results_summary.csv\")\n",
        "    \n",
        "    # Create comparison by technique\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"COMPARISON BY TECHNIQUE\")\n",
        "    print(\"-\"*50)\n",
        "    \n",
        "    technique_comparison = summary_df.groupby('Privacy_Technique').agg({\n",
        "        'Accuracy': ['mean', 'std'],\n",
        "        'F1-Score': ['mean', 'std'],\n",
        "        'Model': 'count'\n",
        "    }).round(4)\n",
        "    \n",
        "    print(technique_comparison)\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No results found. Please run training sections first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 13: Create Comprehensive Visualizations\n",
        "# ============================================================================\n",
        "\n",
        "if all_results:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CREATING COMPREHENSIVE VISUALIZATIONS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # 1. Privacy vs. Performance Trade-off Analysis\n",
        "    print(\"Creating privacy analysis...\")\n",
        "    plot_privacy_analysis(\n",
        "        all_results,\n",
        "        save_path=f'{RESULTS_PATH}/privacy_analysis_comprehensive.png',\n",
        "        title='Comprehensive Privacy Analysis'\n",
        "    )\n",
        "    \n",
        "    # 2. Model Comparison Bars\n",
        "    print(\"Creating model comparison...\")\n",
        "    plot_comparison_bars(\n",
        "        all_results,\n",
        "        metrics=['accuracy', 'f1_score'],\n",
        "        save_path=f'{RESULTS_PATH}/model_comparison_comprehensive.png',\n",
        "        title='Comprehensive Model Comparison'\n",
        "    )\n",
        "    \n",
        "    # 3. Trade-off Curves for DP\n",
        "    dp_models = {k: v for k, v in all_results.items() if v.get('privacy_technique') == 'DP'}\n",
        "    if dp_models:\n",
        "        print(\"Creating DP trade-off curves...\")\n",
        "        plot_tradeoff_curve(\n",
        "            dp_models,\n",
        "            metric='accuracy',\n",
        "            privacy_param='epsilon',\n",
        "            save_path=f'{RESULTS_PATH}/dp_tradeoff_comprehensive.png',\n",
        "            title='Differential Privacy: Privacy vs. Performance Trade-off'\n",
        "        )\n",
        "    \n",
        "    # 4. Summary Dashboard\n",
        "    print(\"Creating summary dashboard...\")\n",
        "    create_summary_dashboard(\n",
        "        all_results,\n",
        "        save_path=f'{RESULTS_PATH}/summary_dashboard.png'\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ All visualizations created successfully!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No results to visualize\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 14: Statistical Analysis and Final Report\n",
        "# ============================================================================\n",
        "\n",
        "if all_results:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"STATISTICAL ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Extract baseline results for comparison\n",
        "    baseline_models = {k: v for k, v in all_results.items() if v.get('privacy_technique') == 'None'}\n",
        "    dp_models = {k: v for k, v in all_results.items() if v.get('privacy_technique') == 'DP'}\n",
        "    fl_models = {k: v for k, v in all_results.items() if v.get('privacy_technique') == 'FL'}\n",
        "    \n",
        "    print(\"Statistical Analysis Results:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Analyze each dataset\n",
        "    for dataset in ['sleep_edf', 'wesad']:\n",
        "        print(f\"\\n{dataset.upper()} Dataset Analysis:\")\n",
        "        \n",
        "        # Find baseline for this dataset\n",
        "        dataset_baseline = None\n",
        "        for model_name, results in baseline_models.items():\n",
        "            if results.get('dataset') == dataset:\n",
        "                dataset_baseline = results\n",
        "                break\n",
        "        \n",
        "        if dataset_baseline:\n",
        "            baseline_acc = dataset_baseline['metrics']['accuracy']\n",
        "            baseline_f1 = dataset_baseline['metrics']['f1_score']\n",
        "            \n",
        "            print(f\"  Baseline: Accuracy={baseline_acc:.4f}, F1={baseline_f1:.4f}\")\n",
        "            \n",
        "            # Compare DP models\n",
        "            dataset_dp = {k: v for k, v in dp_models.items() if v.get('dataset') == dataset}\n",
        "            if dataset_dp:\n",
        "                print(f\"  DP Models:\")\n",
        "                for model_name, results in dataset_dp.items():\n",
        "                    acc = results['metrics']['accuracy']\n",
        "                    f1 = results['metrics']['f1_score']\n",
        "                    epsilon = results.get('epsilon', 'N/A')\n",
        "                    acc_degradation = baseline_acc - acc\n",
        "                    f1_degradation = baseline_f1 - f1\n",
        "                    print(f\"    {model_name}: Acc={acc:.4f} (-{acc_degradation:.4f}), F1={f1:.4f} (-{f1_degradation:.4f}), Œµ={epsilon}\")\n",
        "            \n",
        "            # Compare FL models\n",
        "            dataset_fl = {k: v for k, v in fl_models.items() if v.get('dataset') == dataset}\n",
        "            if dataset_fl:\n",
        "                print(f\"  FL Models:\")\n",
        "                for model_name, results in dataset_fl.items():\n",
        "                    acc = results['metrics']['accuracy']\n",
        "                    f1 = results['metrics']['f1_score']\n",
        "                    n_clients = results.get('n_clients', 'N/A')\n",
        "                    acc_degradation = baseline_acc - acc\n",
        "                    f1_degradation = baseline_f1 - f1\n",
        "                    print(f\"    {model_name}: Acc={acc:.4f} (-{acc_degradation:.4f}), F1={f1:.4f} (-{f1_degradation:.4f}), Clients={n_clients}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Statistical analysis completed!\")\n",
        "    \n",
        "    # Generate final report\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"GENERATING FINAL REPORT\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Create final report\n",
        "    report = {\n",
        "        'project': 'Privacy-Preserving Health Data Analysis',\n",
        "        'datasets': ['Sleep-EDF', 'WESAD'],\n",
        "        'techniques': ['Baseline', 'Differential Privacy', 'Federated Learning'],\n",
        "        'total_models': len(all_results),\n",
        "        'summary': summary_df.to_dict('records') if 'summary_df' in locals() else [],\n",
        "        'key_findings': []\n",
        "    }\n",
        "    \n",
        "    # Add key findings\n",
        "    # Find best performing models\n",
        "    best_accuracy = max(all_results.items(), key=lambda x: x[1]['metrics']['accuracy'])\n",
        "    best_f1 = max(all_results.items(), key=lambda x: x[1]['metrics']['f1_score'])\n",
        "    \n",
        "    report['key_findings'].extend([\n",
        "        f\"Best Accuracy: {best_accuracy[0]} ({best_accuracy[1]['metrics']['accuracy']:.4f})\",\n",
        "        f\"Best F1-Score: {best_f1[0]} ({best_f1[1]['metrics']['f1_score']:.4f})\"\n",
        "    ])\n",
        "    \n",
        "    # Analyze privacy trade-offs\n",
        "    if dp_models:\n",
        "        dp_accuracies = [results['metrics']['accuracy'] for results in dp_models.values()]\n",
        "        avg_dp_accuracy = np.mean(dp_accuracies)\n",
        "        report['key_findings'].append(f\"Average DP Accuracy: {avg_dp_accuracy:.4f}\")\n",
        "    \n",
        "    if fl_models:\n",
        "        fl_accuracies = [results['metrics']['accuracy'] for results in fl_models.values()]\n",
        "        avg_fl_accuracy = np.mean(fl_accuracies)\n",
        "        report['key_findings'].append(f\"Average FL Accuracy: {avg_fl_accuracy:.4f}\")\n",
        "    \n",
        "    # Save final report\n",
        "    with open(f'{RESULTS_PATH}/final_report.json', 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    \n",
        "    print(\"Final Report Generated:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Project: {report['project']}\")\n",
        "    print(f\"Datasets: {', '.join(report['datasets'])}\")\n",
        "    print(f\"Techniques: {', '.join(report['techniques'])}\")\n",
        "    print(f\"Total Models: {report['total_models']}\")\n",
        "    print(\"\\nKey Findings:\")\n",
        "    for finding in report['key_findings']:\n",
        "        print(f\"  ‚Ä¢ {finding}\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ Final report saved to: {RESULTS_PATH}/final_report.json\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No results for statistical analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# STEP 15: Project Completion Summary\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROJECT COMPLETION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"üéâ Privacy-Preserving Health Data Analysis Project Complete!\")\n",
        "print(\"\\nWhat was accomplished:\")\n",
        "print(\"‚úÖ Preprocessed Sleep-EDF and WESAD datasets\")\n",
        "print(\"‚úÖ Trained baseline LSTM models\")\n",
        "print(\"‚úÖ Implemented Differential Privacy with multiple epsilon values\")\n",
        "print(\"‚úÖ Implemented Federated Learning with multiple client configurations\")\n",
        "print(\"‚úÖ Comprehensive evaluation and comparison\")\n",
        "print(\"‚úÖ Statistical analysis of privacy-performance trade-offs\")\n",
        "print(\"‚úÖ Generated visualizations and final report\")\n",
        "\n",
        "print(f\"\\nResults saved in: {RESULTS_PATH}\")\n",
        "print(\"Files generated:\")\n",
        "print(\"  ‚Ä¢ comprehensive_results_summary.csv\")\n",
        "print(\"  ‚Ä¢ detailed_results_summary.csv\")\n",
        "print(\"  ‚Ä¢ privacy_analysis_comprehensive.png\")\n",
        "print(\"  ‚Ä¢ model_comparison_comprehensive.png\")\n",
        "print(\"  ‚Ä¢ dp_tradeoff_comprehensive.png\")\n",
        "print(\"  ‚Ä¢ summary_dashboard.png\")\n",
        "print(\"  ‚Ä¢ final_report.json\")\n",
        "\n",
        "print(\"\\nNext steps for your thesis:\")\n",
        "print(\"1. Review the results and visualizations\")\n",
        "print(\"2. Write the methodology section using the implemented code\")\n",
        "print(\"3. Analyze the trade-offs between privacy and performance\")\n",
        "print(\"4. Discuss implications for mobile health applications\")\n",
        "print(\"5. Create conclusions and recommendations\")\n",
        "\n",
        "print(\"\\nüöÄ Your project is ready for thesis writing!\")\n",
        "print(\"All code is modular and well-documented for reproducibility.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NOTEBOOK EXECUTION COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nThis consolidated notebook has successfully executed the entire pipeline:\")\n",
        "print(\"1. ‚úÖ Setup and Drive Mount\")\n",
        "print(\"2. ‚úÖ Data Preprocessing (Sleep-EDF & WESAD)\")\n",
        "print(\"3. ‚úÖ Baseline Model Training\")\n",
        "print(\"4. ‚úÖ Differential Privacy Training\")\n",
        "print(\"5. ‚úÖ Federated Learning Training\")\n",
        "print(\"6. ‚úÖ Comprehensive Analysis and Visualization\")\n",
        "print(\"\\nAll results are saved to your Google Drive for future reference.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
