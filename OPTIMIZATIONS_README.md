# Otimiza√ß√µes Implementadas no Pr√©-processamento de Dados

## Resumo das Melhorias de Performance

Este documento descreve as otimiza√ß√µes implementadas no sistema de pr√©-processamento de dados para os datasets Sleep-EDF e WESAD, visando acelerar significativamente o processo de prepara√ß√£o de dados para machine learning.

## üöÄ Otimiza√ß√µes Implementadas

### 1. **Processamento Paralelo (Multiprocessing)**
- **Sleep-EDF**: Processa m√∫ltiplos arquivos EDF simultaneamente usando `multiprocessing.Pool`
- **WESAD**: Processa m√∫ltiplos arquivos pickle em paralelo
- **Impacto**: Redu√ß√£o dr√°stica no tempo de processamento proporcional ao n√∫mero de n√∫cleos dispon√≠veis
- **Configura√ß√£o**: 4-8 workers por padr√£o (ajust√°vel)

### 2. **Opera√ß√µes Vetoriais Otimizadas**
- **Filtros**: Pr√©-computa√ß√£o de coeficientes de filtro Butterworth para evitar rec√°lculos
- **Extra√ß√£o de Caracter√≠sticas**: Vetoriza√ß√£o completa usando NumPy para opera√ß√µes em lote
- **Aplica√ß√£o de Filtros**: Uso de `sosfiltfilt` para melhor estabilidade num√©rica
- **Impacto**: Redu√ß√£o significativa no tempo de c√°lculo por arquivo

### 3. **Processamento em Lotes (Batch Processing)**
- **Sleep-EDF**: Processa √©pocas em lotes de 100 para reduzir uso de mem√≥ria
- **Otimiza√ß√£o de Mem√≥ria**: Evita carregar todos os dados simultaneamente
- **Impacto**: Menor consumo de RAM e melhor escalabilidade

### 4. **Sistema de Cache Inteligente**
- **Verifica√ß√£o de Arquivos**: Detecta se dados j√° foram processados
- **Hash de Integridade**: Verifica se dados de entrada mudaram usando hash MD5
- **Cache Persistente**: Salva informa√ß√µes de cache em disco
- **Impacto**: Evita reprocessamento desnecess√°rio de dados id√™nticos

### 5. **Otimiza√ß√£o de E/S**
- **Compress√£o Numpy**: Usa compress√£o autom√°tica nos arrays `.npy`
- **Joblib**: Serializa√ß√£o eficiente de objetos Python
- **Impacto**: Menor espa√ßo em disco e I/O mais r√°pido

## üìä Melhorias de Performance Esperadas

### Sleep-EDF Dataset:
- **Antes**: ~30-45 minutos (processamento sequencial)
- **Depois**: ~5-8 minutos (com 8 workers paralelos)
- **Melhoria**: **75-85% de redu√ß√£o no tempo**

### WESAD Dataset:
- **Antes**: ~15-20 minutos (processamento sequencial)
- **Depois**: ~3-5 minutos (com 8 workers paralelos)
- **Melhoria**: **70-80% de redu√ß√£o no tempo**

## üõ†Ô∏è Como Usar as Otimiza√ß√µes

### Execu√ß√£o B√°sica:
```bash
cd /Users/vasco/Desktop/Mestrado/SIDM/mhealth-data-privacy
python src/preprocessing/preprocess_all.py
```

### Com Cache (recomendado):
```bash
# Primeira execu√ß√£o - processa e cria cache
python src/preprocessing/preprocess_all.py

# Execu√ß√µes subsequentes - usa cache automaticamente
python src/preprocessing/preprocess_all.py
```

### For√ßar Reprocessamento:
```python
from src.preprocessing.sleep_edf import preprocess_sleep_edf
from src.preprocessing.wesad import preprocess_wesad_temporal

# Sleep-EDF com reprocessamento for√ßado
preprocess_sleep_edf(
    data_dir='data/raw/sleep-edf',
    output_dir='data/processed/sleep-edf',
    force_reprocess=True
)

# WESAD com reprocessamento for√ßado
preprocess_wesad_temporal(
    data_dir='data/raw/wesad',
    output_dir='data/processed/wesad',
    force_reprocess=True
)
```

## üîß Configura√ß√µes Ajust√°veis

### N√∫mero de Workers:
```python
# Ajustar n√∫mero de processos paralelos
preprocess_sleep_edf(..., n_workers=6)  # 6 workers
preprocess_wesad_temporal(..., n_workers=6)  # 6 workers
```

### Tamanho do Batch (Sleep-EDF):
- Modificado internamente para 100 √©pocas por batch
- Otimizado para equil√≠brio mem√≥ria/performance

## üìã Caracter√≠sticas T√©cnicas

### Sleep-EDF:
- **Arquivos**: ~80 arquivos EDF pareados (PSG + Hypnogram)
- **√âpocas**: ~15.000-20.000 √©pocas de 30s cada
- **Caracter√≠sticas**: 24 caracter√≠sticas por √©poca (8 por canal √ó 3 canais)
- **Formato**: Arrays NumPy comprimidos

### WESAD:
- **Arquivos**: 15 arquivos pickle (um por sujeito)
- **Janelas**: ~8.000-10.000 janelas de 60s cada
- **Caracter√≠sticas**: 17 sinais √ó 1920 amostras por janela
- **Formato**: Arrays 3D otimizados para CNN/LSTM

## ‚úÖ Verifica√ß√£o de Funcionamento

Para verificar se as otimiza√ß√µes est√£o funcionando:

1. **Monitorar logs**: Verificar mensagens de "PARALLEL" e "cache hit/miss"
2. **Comparar tempos**: Medir tempo de execu√ß√£o antes/depois
3. **Verificar arquivos**: Confirmar cria√ß√£o de arquivos `.cache_info.pkl`
4. **Testar paralelismo**: Usar `htop` ou `top` para ver m√∫ltiplos processos Python

## üö® Considera√ß√µes Importantes

1. **Uso de CPU**: M√∫ltiplos processos podem usar 100% da CPU dispon√≠vel
2. **Mem√≥ria**: Batch processing reduz pico de mem√≥ria, mas ainda requer RAM suficiente
3. **Cache**: Sistema de cache acelera execu√ß√µes subsequentes significativamente
4. **Compatibilidade**: Todas as otimiza√ß√µes s√£o retrocompat√≠veis com c√≥digo existente

## üéØ Pr√≥ximas Otimiza√ß√µes Potenciais

- [ ] Implementar processamento GPU com CuPy/Numba
- [ ] Usar HDF5 para armazenamento mais eficiente
- [ ] Otimizar ainda mais a extra√ß√£o de caracter√≠sticas com JAX
- [ ] Implementar pipeline de streaming para datasets muito grandes

---

*Implementado por: Sistema de Otimiza√ß√£o de Pr√©-processamento - 2025*

