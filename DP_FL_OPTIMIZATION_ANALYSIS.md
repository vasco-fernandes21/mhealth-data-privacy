# ğŸš€ AnÃ¡lise e OtimizaÃ§Ã£o: Differential Privacy & Federated Learning

## ğŸ“Š ANÃLISE DA ESTRUTURA DOS DADOS PROCESSADOS

### Sleep-EDF
- **Shape**: (313,922 train, 66,753 val, 72,330 test) Ã— 24 features
- **Formato**: Dados jÃ¡ extraÃ­dos (features temporais + frequÃªncia)
- **Tipo**: Dados tabulares 2D â†’ Requer windowing para LSTM

### WESAD  
- **Shape**: (715 train, 237 val, 237 test) Ã— 14 channels Ã— 1920 timesteps
- **Formato**: Janelas temporais prÃ©-processadas
- **Tipo**: Dados 3D prontos para LSTM

---

## ğŸ” PROBLEMAS IDENTIFICADOS

### 1. **SLEEP-EDF: Windowing Redundante e Lento**
```python
# âŒ PROBLEMA: Cria windows em CADA Ã©poca de treinamento
def create_windows(X, y, window_size):
    n_windows = n_samples - window_size + 1
    for i in range(n_windows):  # Loop Python lento!
        X_windows[i] = X[i:i+window_size]
        y_windows[i] = y[i+window_size-1]
```

**Impacto**: 
- ~300k windows criadas por Ã©poca
- Loop Python nÃ£o vetorizado
- Tempo desperdiÃ§ado: ~5-10 segundos por Ã©poca

### 2. **DP: DataLoader NÃ£o Otimizado**
```python
# âŒ PROBLEMA: Sem workers paralelos, sem pin_memory
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
```

**Impacto**:
- I/O sÃ­ncrono (bloqueante)
- Sem prefetching de dados
- GPU fica ociosa esperando dados

### 3. **FL: CriaÃ§Ã£o de Windows Repetida por Cliente**
```python
# âŒ PROBLEMA: Cada cliente recria windows
def client_fn(cid: str):
    X_client, y_client = client_datasets[int(cid)]
    # Windows criadas aqui = N_clients Ã— tempo
```

**Impacto**:
- 3-5 clientes Ã— tempo de windowing
- MemÃ³ria duplicada
- SimulaÃ§Ã£o mais lenta

### 4. **DP: Augmentation em Tempo de Treino**
```python
# âŒ PROBLEMA: Augmentation determinÃ­stica a cada treino
def _augment_temporal(X, noise_std=0.01, max_time_shift=8):
    # Loop Python para time shifts
    for i in range(n_samples):
        if shift != 0:
            X_aug[i] = np.pad(...)  # OperaÃ§Ã£o lenta
```

**Impacto**:
- Augmentation poderia ser prÃ©-calculada
- Loops Python lentos
- Overhead em cada Ã©poca

### 5. **FL: Sem Cache de Modelo Base**
```python
# âŒ PROBLEMA: Modelo criado N vezes
def client_fn(cid: str):
    model = SimpleLSTM(...).to(device)  # Nova inicializaÃ§Ã£o
```

**Impacto**:
- InicializaÃ§Ã£o repetida
- Overhead de memÃ³ria
- Tempo de setup por round

---

## âœ… OTIMIZAÃ‡Ã•ES PROPOSTAS

### ğŸ¯ **1. PRÃ‰-PROCESSAR WINDOWS UMA VEZ (Sleep-EDF)**

#### Antes:
```python
# Dados salvos: X_train.npy (313922, 24)
# Windows criadas em runtime
```

#### Depois:
```python
# Salvar dados jÃ¡ em formato windowed
# X_train_windows.npy (313913, 10, 24)  â† Pronto para LSTM!
```

**ImplementaÃ§Ã£o**:
```python
def save_windowed_data(data_dir: str, window_size: int = 10):
    """PrÃ©-processa e salva dados em formato windowed"""
    X_train = np.load(f"{data_dir}/X_train.npy")
    y_train = np.load(f"{data_dir}/y_train.npy")
    
    # VetorizaÃ§Ã£o usando view + stride tricks
    from numpy.lib.stride_tricks import sliding_window_view
    X_windows = sliding_window_view(X_train, window_size, axis=0)
    X_windows = X_windows.transpose(0, 2, 1)  # (n_windows, window, features)
    y_windows = y_train[window_size-1:]  # Labels alinhados
    
    np.save(f"{data_dir}/X_train_windows.npy", X_windows)
    np.save(f"{data_dir}/y_train_windows.npy", y_windows)
```

**Ganho Esperado**: 
- âš¡ **5-10s por Ã©poca** eliminados
- ğŸ“‰ ReduÃ§Ã£o de 30-40% no tempo total de treino
- ğŸ”„ Uma Ãºnica vez no prÃ©-processamento

---

### ğŸ¯ **2. OTIMIZAR DATALOADERS (DP & FL)**

#### Antes:
```python
train_loader = DataLoader(dataset, batch_size=64, shuffle=True)
```

#### Depois:
```python
train_loader = DataLoader(
    dataset, 
    batch_size=64, 
    shuffle=True,
    num_workers=4,           # âœ… Paralelo
    pin_memory=True,         # âœ… GPU transfer rÃ¡pido
    persistent_workers=True, # âœ… Reutiliza workers
    prefetch_factor=2,       # âœ… Prefetch batches
    drop_last=True           # âœ… DP requer batch fixo
)
```

**Ganho Esperado**:
- âš¡ **20-30% mais rÃ¡pido** por Ã©poca
- ğŸ¯ GPU utilizaÃ§Ã£o aumenta de ~60% â†’ ~90%
- ğŸ“Š Throughput aumenta ~1.5Ã—

---

### ğŸ¯ **3. PRÃ‰-CALCULAR AUGMENTATION (DP)**

#### Antes:
```python
# Augmentation em cada Ã©poca
X_train_aug = _augment_temporal(X_train, seed=SEED)
```

#### Depois:
```python
# Salvar augmented data uma vez
def save_augmented_data(data_dir: str, n_augmentations: int = 2):
    X_train = np.load(f"{data_dir}/X_train.npy")
    y_train = np.load(f"{data_dir}/y_train.npy")
    
    X_aug_list = [X_train]
    y_aug_list = [y_train]
    
    for i in range(n_augmentations):
        X_aug = _augment_temporal(X_train, seed=SEED+i)
        X_aug_list.append(X_aug)
        y_aug_list.append(y_train)
    
    X_all = np.concatenate(X_aug_list, axis=0)
    y_all = np.concatenate(y_aug_list, axis=0)
    
    np.save(f"{data_dir}/X_train_augmented.npy", X_all)
    np.save(f"{data_dir}/y_train_augmented.npy", y_all)
```

**Ganho Esperado**:
- âš¡ **2-3s por Ã©poca** eliminados
- ğŸ”„ Augmentation determinÃ­stica garantida
- ğŸ’¾ Trade-off: +2Ã— storage

---

### ğŸ¯ **4. CACHE DE WINDOWED DATA (FL)**

#### Antes:
```python
def partition_data(X_train, y_train, num_clients):
    # Windows criadas por cliente
    client_datasets = []
    for i in range(num_clients):
        X_windows, y_windows = create_windows(X_client, y_client)
        client_datasets.append((X_windows, y_windows))
```

#### Depois:
```python
# Usar dados prÃ©-windowed
X_train_windows = np.load("X_train_windows.npy")
y_train_windows = np.load("y_train_windows.npy")

def partition_windowed_data(X_windows, y_windows, num_clients):
    # Particionar dados jÃ¡ processados
    dataset_size = len(X_windows)
    client_size = dataset_size // num_clients
    indices = np.random.permutation(dataset_size)
    
    client_datasets = []
    for i in range(num_clients):
        start = i * client_size
        end = start + client_size if i < num_clients - 1 else dataset_size
        client_datasets.append((X_windows[indices[start:end]], 
                               y_windows[indices[start:end]]))
    return client_datasets
```

**Ganho Esperado**:
- âš¡ **10-15s** eliminados por run
- ğŸš€ InicializaÃ§Ã£o de clientes ~5Ã— mais rÃ¡pida
- ğŸ’¾ MemÃ³ria mais eficiente (sem duplicaÃ§Ã£o)

---

### ğŸ¯ **5. OTIMIZAR TRAINING LOOPS (DP)**

#### Antes:
```python
def train_one_epoch_dp(model, loader, criterion, optimizer, device, privacy_engine):
    for batch_idx, (batch_X, batch_y) in enumerate(loader):
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        
        # ImpressÃ£o frequente (overhead)
        if (batch_idx + 1) % 3 == 0:
            print(f"Batch {batch_idx + 1}/{len(loader)} - Loss: {loss.item():.4f}")
```

#### Depois:
```python
def train_one_epoch_dp(model, loader, criterion, optimizer, device, privacy_engine):
    # Progress bar com tqdm (mais eficiente)
    pbar = tqdm(loader, desc="Training", leave=False)
    
    for batch_X, batch_y in pbar:
        batch_X, batch_y = batch_X.to(device, non_blocking=True)
        batch_y = batch_y.to(device, non_blocking=True)
        
        optimizer.zero_grad(set_to_none=True)  # âœ… Mais rÃ¡pido
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()
        
        # Update progress bar (sem overhead)
        pbar.set_postfix({'loss': loss.item()})
```

**Ganho Esperado**:
- âš¡ **5-10%** mais rÃ¡pido por Ã©poca
- ğŸ“Š Melhor visualizaÃ§Ã£o de progresso
- ğŸ¯ `non_blocking=True` + `set_to_none=True`

---

### ğŸ¯ **6. MIXED PRECISION TRAINING (DP & FL)**

```python
# Antes: FP32 padrÃ£o
model = SimpleLSTM(...).to(device)

# Depois: FP16/BF16 para aceleraÃ§Ã£o
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for batch_X, batch_y in loader:
    with autocast():  # âœ… OperaÃ§Ãµes em FP16
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

**Ganho Esperado**:
- âš¡ **30-50%** mais rÃ¡pido (se GPU suporta)
- ğŸ’¾ 50% menos memÃ³ria GPU
- âš ï¸ Requer GPU moderna (Volta+, M1/M2/M3)

---

### ğŸ¯ **7. COMPILAÃ‡ÃƒO DE MODELO (PyTorch 2.0+)**

```python
# Antes
model = SimpleLSTM(...).to(device)

# Depois: torch.compile
model = SimpleLSTM(...).to(device)
model = torch.compile(model, mode='reduce-overhead')  # âœ… JIT compilation
```

**Ganho Esperado**:
- âš¡ **10-20%** mais rÃ¡pido
- ğŸ¯ Funciona bem com LSTMs
- âš ï¸ Requer PyTorch 2.0+

---

## ğŸ“ˆ ESTIMATIVA DE GANHOS TOTAIS

### **Sleep-EDF DP**
| OtimizaÃ§Ã£o | Ganho | Impacto Cumulativo |
|------------|-------|-------------------|
| Pre-windowing | -5s/Ã©poca | **30-40%** |
| DataLoader otimizado | -20% tempo | **+20%** |
| Training loop | -5% | **+5%** |
| Mixed precision | -30% (GPU) | **+30%** |
| **TOTAL** | | **ğŸš€ 50-60% mais rÃ¡pido** |

### **WESAD DP**
| OtimizaÃ§Ã£o | Ganho | Impacto Cumulativo |
|------------|-------|-------------------|
| Pre-augmentation | -2s/Ã©poca | **15-20%** |
| DataLoader otimizado | -20% | **+20%** |
| Training loop | -5% | **+5%** |
| Mixed precision | -30% (GPU) | **+30%** |
| **TOTAL** | | **ğŸš€ 45-55% mais rÃ¡pido** |

### **Federated Learning**
| OtimizaÃ§Ã£o | Ganho | Impacto Cumulativo |
|------------|-------|-------------------|
| Pre-windowing (Sleep-EDF) | -10s setup | **20-25%** |
| DataLoader otimizado | -15% | **+15%** |
| Cached clients | -20% | **+20%** |
| **TOTAL** | | **ğŸš€ 40-50% mais rÃ¡pido** |

---

## ğŸ› ï¸ PLANO DE IMPLEMENTAÃ‡ÃƒO

### **Fase 1: PrÃ©-processamento (Alta Prioridade)**
1. âœ… Adicionar funÃ§Ã£o `save_windowed_data` em `preprocessing/sleep_edf.py`
2. âœ… Adicionar funÃ§Ã£o `save_augmented_data` em `preprocessing/wesad.py`
3. âœ… Executar prÃ©-processamento uma vez
4. âœ… Atualizar funÃ§Ãµes de carregamento

### **Fase 2: DataLoaders (MÃ©dia Prioridade)**
1. âœ… Atualizar todos os DataLoaders com workers paralelos
2. âœ… Adicionar `pin_memory` e `persistent_workers`
3. âœ… Testar impacto na velocidade

### **Fase 3: Training Loops (MÃ©dia Prioridade)**
1. âœ… Substituir prints por tqdm
2. âœ… Adicionar `non_blocking=True`
3. âœ… Usar `set_to_none=True` em `zero_grad()`

### **Fase 4: Advanced (Baixa Prioridade)**
1. âš ï¸ Testar mixed precision (se GPU disponÃ­vel)
2. âš ï¸ Testar torch.compile (PyTorch 2.0+)
3. âš ï¸ Profiling detalhado com `torch.profiler`

---

## ğŸ“ RECOMENDAÃ‡Ã•ES ESPECÃFICAS

### **Para Differential Privacy**
- âœ… **CrÃ­tico**: Pre-windowing (Sleep-EDF) e DataLoader otimizado
- âœ… **Importante**: Pre-augmentation (WESAD)
- âš ï¸ **Opcional**: Mixed precision (ganho depende de GPU)

### **Para Federated Learning**
- âœ… **CrÃ­tico**: Pre-windowing (Sleep-EDF)
- âœ… **Importante**: DataLoader com workers
- âš ï¸ **Opcional**: Client caching (complexidade vs ganho)

### **Compatibilidade**
- âœ… Todas otimizaÃ§Ãµes Fase 1-3 sÃ£o compatÃ­veis com Opacus (DP)
- âœ… Flower (FL) suporta todas otimizaÃ§Ãµes propostas
- âš ï¸ Mixed precision: testar compatibilidade com Opacus
- âš ï¸ torch.compile: pode ter issues com DPLSTM

---

## ğŸ¯ PRÃ“XIMOS PASSOS

1. **Implementar Fase 1** (prÃ©-processamento)
   - Modificar `preprocessing/sleep_edf.py`
   - Modificar `preprocessing/wesad.py`
   - Executar prÃ©-processamento

2. **Atualizar Scripts de Treino**
   - Modificar DataLoaders em todos os scripts
   - Atualizar training loops com tqdm

3. **Benchmarking**
   - Medir tempo antes/depois
   - Comparar mÃ©tricas de performance
   - Documentar ganhos reais

4. **ValidaÃ§Ã£o**
   - Verificar que resultados sÃ£o reprodutÃ­veis
   - Confirmar que DP/FL ainda funcionam corretamente
   - Testar com diferentes configuraÃ§Ãµes

---

## ğŸ“Š MÃ‰TRICAS DE SUCESSO

- â±ï¸ **Tempo de treino reduzido em 40-60%**
- ğŸ¯ **GPU utilizaÃ§Ã£o > 85%**
- ğŸ”„ **Reprodutibilidade mantida**
- âœ… **MÃ©tricas de performance inalteradas**
- ğŸ“ˆ **Throughput aumentado em 1.5-2Ã—**


